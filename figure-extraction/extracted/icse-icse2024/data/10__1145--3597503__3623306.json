[{
  "caption": "Table 4: Comparisions between Prompt 2 and other prompts.",
  "captionBoundary": {
    "x1": 53.50199890136719,
    "x2": 294.037353515625,
    "y1": 294.08734130859375,
    "y2": 299.7179870605469
  },
  "figType": "Table",
  "imageText": ["Prompts", "P1", "P3", "P4", "P5", "EM-T", "P-value", "(P2", "is", "superior)", "4.20E-06", "7.69E-09", "2.24E-06", "0.5320", "BLEU-T", "P-value", "(P2", "is", "superior)", "9.44E-09", "2.30E-09", "1.26E-07", "0.0039"],
  "name": "4",
  "page": 5,
  "regionBoundary": {
    "x1": 57.599999999999994,
    "x2": 288.0,
    "y1": 308.64,
    "y2": 335.03999999999996
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/icse-icse2024/figures/10_1145-3597503_3623306-Table4-1.png"
}, {
  "caption": "Table 3: Impact on trainset and validset.",
  "captionBoundary": {
    "x1": 225.052001953125,
    "x2": 386.6462097167969,
    "y1": 179.56735229492188,
    "y2": 185.197998046875
  },
  "figType": "Table",
  "imageText": ["P1", "18.1", "70.77", "18.28", "70.44", "16.15", "68.91", "14.08", "63.21", "2.31", "6.93", "P2", "21.55", "74.21", "20.23", "73.52", "17.99", "71.42", "13.45", "61.94", "1.26", "3.57", "P3", "16.21", "71.2", "16.15", "71.32", "13.97", "69.14", "10.4", "62.87", "1.59", "4.34", "P4", "18.28", "71.45", "17.82", "71.32", "16.44", "68.82", "12.36", "62.48", "1.82", "5.02", "P5", "20.11", "76.17", "19.48", "75.62", "17.7", "72.88", "9.94", "51.69", "0.37", "2.62", "Avg", "18.85", "72.76", "18.39", "72.44", "16.45", "70.23", "12.05", "60.44", "1.47", "4.50", "Pr.", "Temperature=0", "Temperature=0.5", "Temperature=1", "Temperature=1.5", "Temperature=2", "EM-T", "BLEU-T", "EM-T", "BLEU-T", "EM-T", "BLEU-T", "EM-T", "BLEU-T", "EM-T", "BLEU-T"],
  "name": "3",
  "page": 5,
  "regionBoundary": {
    "x1": 105.6,
    "x2": 506.4,
    "y1": 199.68,
    "y2": 283.2
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/icse-icse2024/figures/10_1145-3597503_3623306-Table3-1.png"
}, {
  "caption": "Table 2: Impact of different prompts and temperatures on performance of ChatGPT.",
  "captionBoundary": {
    "x1": 135.68899536132812,
    "x2": 476.0024108886719,
    "y1": 85.72634887695312,
    "y2": 91.35699462890625
  },
  "figType": "Table",
  "imageText": ["Pr.", "Temperature=0", "Temperature=0.5", "Temperature=1.0", "Temperature=1.5", "Temperature=2.0", "Avg", "(Tem.‚â§1.5)", "EM-T", "BLEU-T", "EM-T", "BLEU-T", "EM-T", "BLEU-T", "EM-T", "BLEU-T", "EM-T", "BLEU-T", "EM-T", "BLEU-T", "P1", "19.22", "(0.23)", "73.58", "(0.22)", "18.30", "(0.54)", "72.82", "(0.53)", "16.48", "(0.77)", "71.15", "(0.45)", "12.27", "(1.65)", "64.62", "(0.57)", "6.49", "(0.75)", "28.76", "(1.21)", "16.57", "70.54", "P2", "21.48", "(0.33)", "77.49", "(0.27)", "19.76", "(1.01)", "76.40", "(0.95)", "16.66", "(0.77)", "74.12", "(0.29)", "11.69", "(0.71)", "65.48", "(0.10)", "3.59", "(0.57)", "14.82", "(0.24)", "17.40", "73.37", "P3", "16.40", "(0.23)", "75.37", "(0.17)", "15.76", "(0.27)", "74.66", "(0.41)", "13.02", "(1.02)", "71.92", "(1.33)", "9.06", "(0.09)", "63.36", "(0.88)", "3.89", "(0.25)", "21.50", "(0.37)", "13.56", "71.33", "P4", "19.22", "(0.10)", "75.30", "(0.16)", "18.62", "(0.59)", "74.68", "(0.42)", "16.98", "(0.36)", "72.66", "(0.81)", "11.83", "(0.77)", "65.62", "(0.22)", "6.39", "(0.49)", "25.21", "(0.93)", "16.66", "72.06", "P5", "21.16", "(0.44)", "76.66", "(0.29)", "19.93", "(0.37)", "76.35", "(0.43)", "16.89", "(0.85)", "74.69", "(0.78)", "10.48", "(0.50)", "63.96", "(1.08)", "1.78", "(0.75)", "14.25", "(0.29)", "17.11", "72.92", "Avg", "19.50", "75.68", "18.47", "74.98", "16.01", "72.91", "11.06", "64.61", "4.43", "20.91", "16.26", "72.05"],
  "name": "2",
  "page": 5,
  "regionBoundary": {
    "x1": 54.72,
    "x2": 557.28,
    "y1": 105.6,
    "y2": 166.07999999999998
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/icse-icse2024/figures/10_1145-3597503_3623306-Table2-1.png"
}, {
  "caption": "Table 5: Quantitative evaluation results.",
  "captionBoundary": {
    "x1": 93.07600402832031,
    "x2": 254.4639434814453,
    "y1": 85.72634887695312,
    "y2": 91.35699462890625
  },
  "figType": "Table",
  "imageText": ["ChatGPT", "19.39", "23.40", "71.97", "76.25", "ùê∂ùëÖùëÅùêø", "CodeReviewer", "5,451", "13.21", "14.05", "62.67", "63.61", "ChatGPT", "19.60", "22.44", "72.90", "76.55", "ùê∂ùëÖùëÅùëá", "CodeReviewer", "9,117", "15.75", "16.31", "62.01", "62.47", "ChatGPT", "19.52", "22.78", "72.56", "76.44", "ùê∂ùëÖùëÅ", "CodeReviewer", "14,568", "14.84", "15.50", "62.25", "62.88", "ChatGPT", "16.70", "19.47", "68.26", "75.12", "ùê∂ùëÖ", "CodeReviewer", "13,104", "32.49", "32.55", "83.39", "83.50", "Dataset", "Tool", "#Samples", "EM", "EM-T", "BLEU", "BLEU-T"],
  "name": "5",
  "page": 6,
  "regionBoundary": {
    "x1": 61.919999999999995,
    "x2": 286.08,
    "y1": 105.6,
    "y2": 189.12
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/icse-icse2024/figures/10_1145-3597503_3623306-Table5-1.png"
}, {
  "caption": "Figure 3: Data quality of CodeReview and CodeReview-New.",
  "captionBoundary": {
    "x1": 317.9549865722656,
    "x2": 558.1278686523438,
    "y1": 197.87936401367188,
    "y2": 203.510009765625
  },
  "figType": "Figure",
  "imageText": ["ConSugg", "VagSugg", "VagQues", "Information", "CR", "CRN", "250", "200", "150", "100", "50", "0", "46", "65", "59", "40", "95", "95", "Perfect", "Partial", "Not", "Relevance", "CR", "CRN", "250", "200", "150", "100", "50", "0", "36", "21", "29", "29", "135", "150"],
  "name": "3",
  "page": 6,
  "regionBoundary": {
    "x1": 328.8,
    "x2": 547.1999999999999,
    "y1": 82.56,
    "y2": 184.32
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/icse-icse2024/figures/10_1145-3597503_3623306-Figure3-1.png"
}, {
  "caption": "Table 7: Results of root cause analysis.",
  "captionBoundary": {
    "x1": 96.16500854492188,
    "x2": 251.37535095214844,
    "y1": 85.72634887695312,
    "y2": 91.35699462890625
  },
  "figType": "Table",
  "imageText": ["Inaccurate", "Measurement", "Incorrect", "Prediction", "Type", "IO", "UGF", "CSD", "RI", "NDK", "UL", "UC", "MF", "#Samples", "13", "2", "19", "8", "107", "32", "11", "14"],
  "name": "7",
  "page": 9,
  "regionBoundary": {
    "x1": 60.0,
    "x2": 288.0,
    "y1": 105.6,
    "y2": 132.0
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/icse-icse2024/figures/10_1145-3597503_3623306-Table7-1.png"
}, {
  "caption": "Table 8: Results of mitigation strategies.",
  "captionBoundary": {
    "x1": 356.7090148925781,
    "x2": 519.1460571289062,
    "y1": 85.72634887695312,
    "y2": 91.35699462890625
  },
  "figType": "Table",
  "imageText": ["UL", "32", "24", "-", "24", "22", "9", "-", "31", "UC", "11", "-", "6", "6", "6", "-", "4", "10", "Strategy", "#Samples", "GPT-3.5", "GPT-4", "Loc.", "Exp.", "Total", "Dir.", "Loc.", "Exp.", "Total"],
  "name": "8",
  "page": 9,
  "regionBoundary": {
    "x1": 325.92,
    "x2": 550.0799999999999,
    "y1": 105.6,
    "y2": 141.12
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/icse-icse2024/figures/10_1145-3597503_3623306-Table8-1.png"
}, {
  "caption": "Figure 1: Overview of our study",
  "captionBoundary": {
    "x1": 242.16400146484375,
    "x2": 369.830810546875,
    "y1": 212.69137573242188,
    "y2": 218.322021484375
  },
  "figType": "Figure",
  "imageText": ["Tools", "Bad", "Cases", "Comparative", "Results", "Optimal", "Setting", "CodeReviewer", "(CodeT5)", "ChatGPT", "(GPT-3.5-turbo,", "GPT-4)", "-Case", "Study", "RQ4:", "Root", "Cause", "Analysis", "and", "Potential", "Mitigation", "RQ3:", "Understanding", "Strengths", "and", "Weaknesses", "of", "ChatGPT", "-Qualitative", "Comparative", "Analysis", "-Quantitative", "Comparative", "Analysis", "RQ2:", "Effectiveness", "of", "ChatGPT", "on", "Code", "Refinement", "RQ1:", "Impact", "of", "ChatGPT", "Settings", "-Prompt", "and", "Temperature", "Research", "Questions", "CodeReview-NewLanguage", "(240", "repos)", "CodeReview-NewTime", "(232", "repos)", "CodeReview", "(829", "repos)", "Datasets"],
  "name": "1",
  "page": 2,
  "regionBoundary": {
    "x1": 72.0,
    "x2": 540.0,
    "y1": 82.56,
    "y2": 199.2
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/icse-icse2024/figures/10_1145-3597503_3623306-Figure1-1.png"
}, {
  "caption": "Figure 5: An example of unclear location and the mitigation.",
  "captionBoundary": {
    "x1": 317.9549865722656,
    "x2": 558.1912841796875,
    "y1": 281.0833435058594,
    "y2": 286.7139892578125
  },
  "figType": "Figure",
  "imageText": ["Fix", "Strategy", "2:", "ChatGPT", "(GPT-4)", "+", "Original", "Review.", "GPT-4", "Explanations:", "‚ÄúBased", "on", "the", "code", "review,", "the", "reviewer", "has", "requested", "to", "change", "the", "comment", "mentioning", "markTable-", "ForAnalyzer", "to", "markTableForAnalyze.", "Here‚Äòs", "the", "revised", "code:", "‚Ä¶‚Äù", "Fix", "Strategy", "1:", "ChatGPT", "(GPT-3.5)", "+", "Revised", "Review.", "Revised", "Review:", "‚ÄúAt", "the", "line:", "back", "into", "markTableForAnalyze,", "change", "it", "to", "`markTableForAnalyze`", "(without", "r).‚Äù", "-", "private", "void", "analyzeTables()", "{", "+private", "void", "markTableForAnalyze", "()", "{", "//", "take", "a", "local", "copy", "and", "clear", "because", "in", "rare", "cases", "we", "can", "call", "-", "//", "back", "into", "markTableForAnalyzer", "while", "iterating", "here", "+", "//", "back", "into", "markTableForAnalyze", "while", "iterating", "here", "HashSet<Table>", "tablesToAnalyzeLocal", "=", "tablesToAnalyze;", "private", "void", "analyzeTables()", "{", "//", "take", "a", "local", "copy", "and", "clear", "because", "in", "rare", "cases", "we", "can", "call", "-", "//", "back", "into", "markTableForAnalyzer", "while", "iterating", "here", "+", "//", "back", "into", "markTableForAnalyze", "while", "iterating", "here", "HashSet<Table>", "tablesToAnalyzeLocal", "=", "tablesToAnalyze;", "ChatGPT", "(GPT-3.5)", "Result:", "Ground", "Truth:", "Original", "Review:", "‚Äú`markTableForAnalyze`", "(without", "r)‚Äù", "SMU", "Classification:", "Restricted"],
  "name": "5",
  "page": 7,
  "regionBoundary": {
    "x1": 322.56,
    "x2": 611.52,
    "y1": 82.56,
    "y2": 267.36
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/icse-icse2024/figures/10_1145-3597503_3623306-Figure5-1.png"
}, {
  "caption": "Figure 6: An example of unclear changes and the mitigation.",
  "captionBoundary": {
    "x1": 317.9549865722656,
    "x2": 558.1299438476562,
    "y1": 389.1113586425781,
    "y2": 394.74200439453125
  },
  "figType": "Figure",
  "imageText": ["Fix", "Strategy", "2:", "ChatGPT", "(GPT-4)", "+", "Original", "Review.", "GPT-4", "Explanations:", "‚ÄúInstead", "of", "modifying", "the", "`data`", "object", "and", "then", "returning", "it,", "we", "can", "simply", "return", "the", "result", "of", "`data.apply", "{", "...", "}`", "directly.", "This", "makes", "the", "code", "more", "concise", "and", "easier", "to", "read.", "Here‚Äòs", "the", "revised", "code:", "‚Ä¶‚Äù", "Revised", "Review:", "‚Äúreturn", "the", "result", "of", "`data.apply", "{", "...", "}`", "directly.‚Äù", "Fix", "Strategy", "1:", "ChatGPT", "(GPT-3.5)", "+", "Revised", "Review.", "private", "fun", "genericError(data:", "Payload):", "Payload", "{", "-", "data.apply", "{", "-", "success", "=", "false", "-", "resultType", "=", "GENERIC_ERROR", "-", "result", "=", "arrayOfNulls(0)", "-", "}", "+data.success", "=", "false", "+data.resultType", "=", "GENERIC_ERROR", "+data.result", "=", "arrayOfNulls(0)", "return", "data", "}", "private", "fun", "genericError(data:", "Payload):", "Payload", "{", "+", "return", "data.apply", "{", "-", "data.apply", "{", "success", "=", "false", "resultType", "=", "GENERIC_ERROR", "result", "=", "arrayOfNulls(0)", "}", "-", "return", "data", "}", "ChatGPT", "(GPT-3.5)", "Result:", "Ground", "Truth:", "SMU", "Classification:", "Restricted", "Original", "Review:", "‚Äúreturn", "data", "directly‚Äù"],
  "name": "6",
  "page": 8,
  "regionBoundary": {
    "x1": 322.56,
    "x2": 611.52,
    "y1": 161.76,
    "y2": 374.4
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/icse-icse2024/figures/10_1145-3597503_3623306-Figure6-1.png"
}, {
  "caption": "Figure 7: An example of model fallacy.",
  "captionBoundary": {
    "x1": 360.06201171875,
    "x2": 516.0882568359375,
    "y1": 505.5003662109375,
    "y2": 511.1310119628906
  },
  "figType": "Figure",
  "imageText": ["Schema::table('settings',", "function", "(Blueprint", "$table)", "{", "-", "$table->tinyInteger('labels_display_model‚Äô)", "+", "$table->boolean('labels_display_model‚Äô)", "-", "->default(1);", "+", "->default(false);", "Schema::table('settings',", "function", "(Blueprint", "$table)", "{", "-", "$table->tinyInteger('labels_display_model‚Äô)", "+", "$table->boolean('labels_display_model‚Äô)", "-", "->default(1);", "+", "->default(0);", "ChatGPT", "(GPT-3.5)", "Result:", "Ground", "Truth:", "SMU", "Classification:", "Restricted", "Original", "Review:", "‚ÄúThis", "should", "probably", "be", "boolean,", "with", "a", "default", "of", "0,", "so", "we", "don't", "mess", "up", "other", "people's", "existing", "settings.‚Äù"],
  "name": "7",
  "page": 8,
  "regionBoundary": {
    "x1": 316.8,
    "x2": 602.4,
    "y1": 411.84,
    "y2": 491.03999999999996
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/icse-icse2024/figures/10_1145-3597503_3623306-Figure7-1.png"
}]