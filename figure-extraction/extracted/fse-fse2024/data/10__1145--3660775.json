[{
  "caption": "Fig. 5. On the le : the state of Snake. On the right: the rewards at each time step of Snake.",
  "captionBoundary": {
    "x1": 73.8667984008789,
    "x2": 412.13385009765625,
    "y1": 451.0455017089844,
    "y2": 455.447998046875
  },
  "figType": "Figure",
  "imageText": [],
  "name": "5",
  "page": 10,
  "regionBoundary": {
    "x1": 92.64,
    "x2": 393.12,
    "y1": 325.92,
    "y2": 436.32
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/fse-fse2024/figures/10_1145-3660775-Figure5-1.png"
}, {
  "caption": "Fig. 3. The modified reinforcement-learning loop.",
  "captionBoundary": {
    "x1": 151.71400451660156,
    "x2": 334.2877197265625,
    "y1": 380.947509765625,
    "y2": 385.3500061035156
  },
  "figType": "Figure",
  "imageText": [],
  "name": "3",
  "page": 6,
  "regionBoundary": {
    "x1": 163.68,
    "x2": 322.08,
    "y1": 276.96,
    "y2": 366.24
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/fse-fse2024/figures/10_1145-3660775-Figure3-1.png"
}, {
  "caption": "Fig. 4. The intersection for the Tra ic Control system.",
  "captionBoundary": {
    "x1": 143.79100036621094,
    "x2": 342.208984375,
    "y1": 306.6065979003906,
    "y2": 311.00909423828125
  },
  "figType": "Figure",
  "imageText": ["(a)", "An", "EW", "tra", "ic", "light", "configuration.", "(b)", "An", "NSL", "tra", "ic", "light", "configuration."],
  "name": "4",
  "page": 9,
  "regionBoundary": {
    "x1": 64.8,
    "x2": 421.44,
    "y1": 145.92,
    "y2": 289.92
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/fse-fse2024/figures/10_1145-3660775-Figure4-1.png"
}, {
  "caption": "Fig. 8. Snake: on the le -hand side, the average reward value per reward modifier value. On the right-hand side, the average undesirable behavior ratio per reward modifier value.",
  "captionBoundary": {
    "x1": 45.82809829711914,
    "x2": 440.17535400390625,
    "y1": 468.9735107421875,
    "y2": 484.33502197265625
  },
  "figType": "Figure",
  "imageText": [],
  "name": "8",
  "page": 13,
  "regionBoundary": {
    "x1": 77.75999999999999,
    "x2": 397.44,
    "y1": 336.0,
    "y2": 454.08
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/fse-fse2024/figures/10_1145-3660775-Figure8-1.png"
}, {
  "caption": "Fig. 7. Tra ic Control: on the le -hand side, the average reward value per reward modifier value. On the right-hand side, the average undesirable behavior ratio per reward modifier value.",
  "captionBoundary": {
    "x1": 45.82809829711914,
    "x2": 440.1737976074219,
    "y1": 218.20748901367188,
    "y2": 233.56900024414062
  },
  "figType": "Figure",
  "imageText": [],
  "name": "7",
  "page": 13,
  "regionBoundary": {
    "x1": 76.8,
    "x2": 397.44,
    "y1": 84.96,
    "y2": 203.04
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/fse-fse2024/figures/10_1145-3660775-Figure7-1.png"
}, {
  "caption": "Fig. 1. An toy example of a decision tree classifier, with 2 labels: “Go to Sleep” and “Don’t go to sleep”.",
  "captionBoundary": {
    "x1": 53.51409912109375,
    "x2": 432.48773193359375,
    "y1": 647.4033813476562,
    "y2": 651.805908203125
  },
  "figType": "Figure",
  "imageText": [],
  "name": "1",
  "page": 2,
  "regionBoundary": {
    "x1": 144.0,
    "x2": 342.24,
    "y1": 552.96,
    "y2": 633.12
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/fse-fse2024/figures/10_1145-3660775-Figure1-1.png"
}, {
  "caption": "Fig. 10. Tra ic Control: Comparing our approach and VIPER.",
  "captionBoundary": {
    "x1": 129.11399841308594,
    "x2": 356.8870544433594,
    "y1": 361.05950927734375,
    "y2": 365.4620056152344
  },
  "figType": "Figure",
  "imageText": [],
  "name": "10",
  "page": 17,
  "regionBoundary": {
    "x1": 77.75999999999999,
    "x2": 409.44,
    "y1": 230.88,
    "y2": 341.28
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/fse-fse2024/figures/10_1145-3660775-Figure10-1.png"
}, {
  "caption": "Fig. 6. Aurora: on the le -hand side, the average reward values per reward modifiers value. On the right-hand side, the average undesirable behavior ratio per reward modifier value.",
  "captionBoundary": {
    "x1": 45.82809829711914,
    "x2": 440.1737365722656,
    "y1": 218.3544921875,
    "y2": 233.71600341796875
  },
  "figType": "Figure",
  "imageText": [],
  "name": "6",
  "page": 12,
  "regionBoundary": {
    "x1": 75.84,
    "x2": 397.44,
    "y1": 84.96,
    "y2": 204.48
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/fse-fse2024/figures/10_1145-3660775-Figure6-1.png"
}, {
  "caption": "Fig. 2. (Borrowed from [Bha 2019]) The main loop of reinforcement learning.",
  "captionBoundary": {
    "x1": 97.58789825439453,
    "x2": 388.41259765625,
    "y1": 405.97149658203125,
    "y2": 410.3739929199219
  },
  "figType": "Figure",
  "imageText": [],
  "name": "2",
  "page": 3,
  "regionBoundary": {
    "x1": 144.0,
    "x2": 342.24,
    "y1": 316.8,
    "y2": 391.2
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/fse-fse2024/figures/10_1145-3660775-Figure2-1.png"
}, {
  "caption": "Fig. 11. Snake: Comparing our approach and VIPER.",
  "captionBoundary": {
    "x1": 145.07400512695312,
    "x2": 340.9267272949219,
    "y1": 301.3074951171875,
    "y2": 305.7099914550781
  },
  "figType": "Figure",
  "imageText": [],
  "name": "11",
  "page": 18,
  "regionBoundary": {
    "x1": 77.75999999999999,
    "x2": 409.44,
    "y1": 170.88,
    "y2": 281.28
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/fse-fse2024/figures/10_1145-3660775-Figure11-1.png"
}, {
  "caption": "Fig. 9. Tra ic decision tree: diagram of a specific path.",
  "captionBoundary": {
    "x1": 141.46499633789062,
    "x2": 344.53564453125,
    "y1": 486.1875,
    "y2": 490.5899963378906
  },
  "figType": "Figure",
  "imageText": [],
  "name": "9",
  "page": 15,
  "regionBoundary": {
    "x1": 144.0,
    "x2": 342.24,
    "y1": 355.68,
    "y2": 471.35999999999996
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/fse-fse2024/figures/10_1145-3660775-Figure9-1.png"
}]