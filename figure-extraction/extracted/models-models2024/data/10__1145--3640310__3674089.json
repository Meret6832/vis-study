[{
  "caption": "Table 2: Datasets used for training the recommenders for the three DSLs.",
  "captionBoundary": {
    "x1": 317.65899658203125,
    "x2": 558.2049560546875,
    "y1": 590.7791137695312,
    "y2": 607.3690185546875
  },
  "figType": "Table",
  "imageText": ["MAR/Ecore", "67,", "322", "8,", "541", "8,", "541", "Emfatic", "MAR/Xtext", "5,", "061", "2,", "762", "2,", "762", "Xtext", "ModelSet", "10,", "595", "5,", "568", "1,", "204", "Domain", "DSL", "Dataset", "#Models", "(Raw)", "#Models", "(Dedup)", "#Models", "(Filtered)", "Applied", "to"],
  "name": "2",
  "page": 5,
  "regionBoundary": {
    "x1": 330.71999999999997,
    "x2": 545.28,
    "y1": 525.6,
    "y2": 585.12
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/models-models2024/figures/10_1145-3640310_3674089-Table2-1.png"
}, {
  "caption": "Figure 3: ModelMate plug-in for Emfatic. (1) Fragment completion suggestion. (2) Identifier suggestion.",
  "captionBoundary": {
    "x1": 317.9549865722656,
    "x2": 559.810546875,
    "y1": 216.45509338378906,
    "y2": 233.04498291015625
  },
  "figType": "Figure",
  "imageText": ["2", "1"],
  "name": "3",
  "page": 5,
  "regionBoundary": {
    "x1": 324.0,
    "x2": 552.0,
    "y1": 82.56,
    "y2": 203.04
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/models-models2024/figures/10_1145-3640310_3674089-Figure3-1.png"
}, {
  "caption": "Table 9: Comparative table of the state-of-the-art recommender systems in the context of MDE.",
  "captionBoundary": {
    "x1": 112.98999786376953,
    "x2": 498.7156677246094,
    "y1": 200.29408264160156,
    "y2": 205.92498779296875
  },
  "figType": "Table",
  "imageText": ["Fragment", "Fine-tuning", "PLMs", "Textual", "syntax", "Any", "with", "textual", "syntax", "MAR", "MAR", "ModelSet", "Yes", "Approach", "Task", "Techniqe", "Level", "Target", "artifacts", "Training", "dataset", "Evaluation", "dataset", "Integration", "Chaaben", "et", "al.", "[5]", "Identifier", "GPT-3", "AST", "UML", "models", "N.A.", "ModelSet", "No", "EcoreBERT", "[31]", "Identifier", "Training", "RoBERTa", "AST", "Ecore", "models", "MAR", "MAR", "No", "MORGAN", "[8]", "Identifier", "ùëò-nn", "+", "graph", "kernels", "AST", "Any", "ModelSet", "BigQuery", "JSON", "ModelSet", "BigQuery", "JSON", "No", "MemoRec", "[6]", "Identifier", "Collaborative", "filtering", "AST", "Ecore", "models", "Ecore555", "Ecore", "GitHub", "Ecore555", "Ecore", "GitHub", "No", "Burgue√±o", "et", "al.", "[4]", "Identifier", "Word", "embedding", "+", "ùëò-nn", "AST", "UML", "models", "Propietary", "dataset", "Propietary", "dataset", "No", "SimIMA", "[1]", "Fragment", "Ensemble", "learning", "AST", "Simulink", "Simulink", "datatset", "Simulink", "datatset", "Yes", "ModelMate", "Identifier", "Line"],
  "name": "9",
  "page": 10,
  "regionBoundary": {
    "x1": 54.72,
    "x2": 578.4,
    "y1": 82.56,
    "y2": 198.23999999999998
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/models-models2024/figures/10_1145-3640310_3674089-Table9-1.png"
}, {
  "caption": "Table 7: Comparison of ModelMate/Emfatic against prompting GPT-3.5 on a sampled version of our test dataset (1, 000 samples for tokens, lines and fragments and 200 for each kind of identifier).",
  "captionBoundary": {
    "x1": 53.50199890136719,
    "x2": 558.2022094726562,
    "y1": 161.2691192626953,
    "y2": 177.8590087890625
  },
  "figType": "Table",
  "imageText": ["GPT-3.5", "80.58", "42.00", "79.00", "72.50", "58.50", "51.5", "54.00", "22.60", "65.80", "23.73", "codegen-multi", "69.24", "41.23", "78.93", "80.49", "52.21", "37.71", "62.87", "14.20", "48.84", "31.65", "codeparrot", "68.71", "41.83", "80.58", "79.78", "50.23", "38.60", "62.72", "13.10", "46.54", "30.87", "gpt2-large", "68.52", "40.95", "78.46", "81.35", "47.41", "39.05", "61.25", "12.60", "45.12", "30.42", "Model", "Accuracy", "class", "name", "super", "name", "attr.", "type", "ref.", "type", "val.", "type", "feature", "name", "EM", "Edit", "Similarity", "BLEU", "Identifier", "Suggestion", "Line", "Fragment"],
  "name": "7",
  "page": 9,
  "regionBoundary": {
    "x1": 61.919999999999995,
    "x2": 550.0799999999999,
    "y1": 83.52,
    "y2": 158.4
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/models-models2024/figures/10_1145-3640310_3674089-Table7-1.png"
}, {
  "caption": "Table 8: Inference time of ModelMate/Emfatic. Average time (ms) of 1, 000 samples per task ¬± the standard deviation.",
  "captionBoundary": {
    "x1": 53.50199890136719,
    "x2": 294.0443420410156,
    "y1": 260.9751281738281,
    "y2": 277.56500244140625
  },
  "figType": "Table",
  "imageText": ["codeparrot", "84.34", "¬±", "40.0", "130.2", "¬±", "43.8", "420.0", "¬±", "714.0", "codegen-multi", "232.2", "¬±", "115.6", "341.9", "¬±", "130.0", "1490.7", "¬±", "2311.6", "gpt2-large", "365.4", "¬±", "217.8", "425.6", "¬±", "191.6", "1877.8", "¬±", "2801.5", "Identifier", "Line", "Fragment"],
  "name": "8",
  "page": 9,
  "regionBoundary": {
    "x1": 62.879999999999995,
    "x2": 285.12,
    "y1": 207.84,
    "y2": 258.24
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/models-models2024/figures/10_1145-3640310_3674089-Table8-1.png"
}, {
  "caption": "Figure 1: Recommendation types exemplified with Emfatic. Gray text is the generated completion. (1) Fragment completion, (2) Line completion, (3) Identifier suggestion.",
  "captionBoundary": {
    "x1": 317.9549865722656,
    "x2": 559.8106689453125,
    "y1": 274.4541015625,
    "y2": 302.00299072265625
  },
  "figType": "Figure",
  "imageText": ["Arc", "suggestions", "Transition", "Place", "(3)", "(2)", "class", "PetriNet", "{", "val", "class", "Place", "{", "attr", "String[1]", "name;", "}", "@namespace(uri=‚Äúhttp://pn‚Äù,", "prefix=‚Äúpn‚Äù)", "package", "petrinet;", "class", "PetriNet", "{", "attr", "String[0..1]", "name;", "val", "Node[*]", "nodes;", "Generated", "line", "@namespace(uri=‚Äúhttp://pn‚Äù,", "prefix=‚Äúpn‚Äù)", "package", "petrinet;", "class", "PetriNet", "{", "attr", "String[0..1]", "name;", "val", "Node[*]", "nodes;", "val", "Transition[*]", "transitions;", "}", "Generated", "fragment", "(1)", "@namespace(uri=‚Äúhttp://pn‚Äù,", "prefix=‚Äúpn‚Äù)", "package", "petrinet;"],
  "name": "1",
  "page": 2,
  "regionBoundary": {
    "x1": 355.68,
    "x2": 520.3199999999999,
    "y1": 83.52,
    "y2": 261.12
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/models-models2024/figures/10_1145-3640310_3674089-Figure1-1.png"
}, {
  "caption": "Table 4: Evaluation results for Xtext.",
  "captionBoundary": {
    "x1": 99.62200164794922,
    "x2": 247.92628479003906,
    "y1": 303.7611083984375,
    "y2": 309.3919982910156
  },
  "figType": "Table",
  "imageText": ["codeparrot", "60.13", "22.38", "43.90", "23.07", "codegen-multi", "58.75", "21.41", "42.02", "22.81", "gpt2", "54.99", "20.32", "38.04", "17.57", "Model", "Accuracy", "EM", "Edit", "Similarity", "BLEU", "Line", "Fragment"],
  "name": "4",
  "page": 7,
  "regionBoundary": {
    "x1": 61.919999999999995,
    "x2": 286.08,
    "y1": 235.67999999999998,
    "y2": 301.44
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/models-models2024/figures/10_1145-3640310_3674089-Table4-1.png"
}, {
  "caption": "Table 3: Results of the evaluation of different models for Emfatic.",
  "captionBoundary": {
    "x1": 173.08299255371094,
    "x2": 438.62310791015625,
    "y1": 200.72108459472656,
    "y2": 206.35198974609375
  },
  "figType": "Table",
  "imageText": ["codegen-mono", "69.10", "45.03", "78.28", "77.24", "52.91", "39.22", "59.35", "14.27", "50.51", "31.21", "codegen-multi", "69.07", "45.19", "78.33", "77.73", "53.45", "39.03", "59.36", "14.37", "50.81", "31.32", "codeparrot", "68.64", "44.25", "77.65", "77.72", "50.84", "37.79", "58.35", "13.90", "48.63", "30.67", "gpt2-large", "68.52", "42.29", "75.41", "76.60", "50.58", "36.87", "57.51", "13.24", "48.53", "29.93", "codegen-nl", "68.02", "41.55", "76.31", "75.75", "50.21", "35.87", "57.23", "12.06", "46.04", "29.11", "gpt2-medium", "67.65", "39.97", "74.24", "75.91", "48.34", "33.66", "54.83", "11.63", "44.36", "28.39", "gpt2", "65.83", "35.19", "70.78", "74.49", "42.15", "28.77", "51.07", "9.16", "41.76", "26.15", "distil-gpt2", "64.02", "29.08", "66.30", "73.15", "36.65", "23.58", "47.02", "6.48", "37.19", "24.09", "Model", "Accuracy", "class", "name", "super", "name", "attr.", "type", "ref.", "type", "val.", "type", "feature", "name", "EM", "Edit", "Similarity", "BLEU", "Identifier", "Suggestion", "Line", "Fragment"],
  "name": "3",
  "page": 7,
  "regionBoundary": {
    "x1": 63.839999999999996,
    "x2": 548.16,
    "y1": 83.52,
    "y2": 198.23999999999998
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/models-models2024/figures/10_1145-3640310_3674089-Table3-1.png"
}, {
  "caption": "Table 1: PLMs considered in ModelMate.",
  "captionBoundary": {
    "x1": 357.1839904785156,
    "x2": 518.6767578125,
    "y1": 527.9871215820312,
    "y2": 533.6180419921875
  },
  "figType": "Table",
  "imageText": ["PLM", "Parameters", "Pre-training", "data", "GPT2", "[23]", "124M", "WebText", "[23]", "GPT2-M", "[23]", "355M", "WebText", "[23]", "GPT2-L", "[23]", "774M", "WebText", "[23]", "DiltilGPT2", "[25]", "82M", "OpenWebText", "[22]", "CodeParrot-small-multi", "110M", "CodeParrot", "dataset", "Codegen-nl", "[20]", "350M", "The", "Pile", "[10]", "Codegen-multi", "[20]", "350M", "BigQuery", "[20]", "Codegen-mono", "[20]", "350M", "BigPython", "[20]", "‚Ä¢", "GPT2", "family", "[23].", "Released", "by", "OpenAI,", "these", "models", "were", "trained", "using", "40GB", "of", "text", "data", "(WebText).", "For", "this", "study,", "we", "focus", "on", "three", "checkpoints:", "GPT2", "(124M", "parameters),", "GPT2-", "M", "(355M", "parameters),", "and", "GPT2-L", "(774M", "parameters).", "‚Ä¢", "DistilGPT2", "[25].", "HuggingFace", "released", "this", "compressed", "ver-", "sion", "of", "GPT2,", "employing", "82M", "parameters.", "It", "was", "pre-trained", "through", "knowledge", "distillation,", "with", "GPT2", "serving", "as", "the", "teacher", "model.", "The", "dataset", "used", "in", "the", "training", "is", "an", "open-", "source", "version", "of", "the", "WebText", "corpus.", "‚Ä¢", "CodeParrot-small5.", "This", "110M", "parameter", "model", "was", "pre-", "trained", "using", "an", "extensive", "corpus", "extracted", "from", "GitHub,", "encompassing", "data", "from", "nine", "programming", "languages.", "‚Ä¢", "Codegen", "family", "[20].", "Salesforce", "released", "a", "series", "of", "mod-", "els", "of", "350M", "parameters.", "Codegen-nl", "was", "pre-trained", "on", "The", "Pile", "[10]", "containing", "both", "natural", "language", "and", "code.", "Codegen-multi", "was", "initialized", "with", "the", "Codegen-nl", "check-", "point", "and", "trained", "on", "a", "diverse", "corpus", "containing", "multiple", "programming", "languages", "from", "GitHub.", "Finally,", "Codegen-", "mono", "was", "initialized", "with", "the", "Codegen-multi", "checkpoint", "and", "trained", "using", "a", "Python", "corpus."],
  "name": "1",
  "page": 3,
  "regionBoundary": {
    "x1": 330.71999999999997,
    "x2": 560.16,
    "y1": 193.92,
    "y2": 525.12
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/models-models2024/figures/10_1145-3640310_3674089-Table1-1.png"
}, {
  "caption": "Table 5: Evaluation results for the Domain entities DSL",
  "captionBoundary": {
    "x1": 194.3780059814453,
    "x2": 417.32763671875,
    "y1": 150.90809631347656,
    "y2": 156.53900146484375
  },
  "figType": "Table",
  "imageText": ["codegen-multi", "77.39", "40.86", "19.49", "33.35", "78.16", "36.99", "59.21", "71.78", "codeparrot", "76.31", "41.38", "20.07", "31.39", "79.20", "34.38", "55.92", "72.19", "gpt2", "69.58", "28.34", "11.87", "20.14", "70.53", "22.21", "43.57", "65.08", "Model", "Accuracy", "entity", "name", "op.", "name", "feature", "name", "feature", "type", "EM", "Edit", "Similarity", "BLEU", "Identifier", "Suggestion", "Line", "Fragment"],
  "name": "5",
  "page": 8,
  "regionBoundary": {
    "x1": 98.88,
    "x2": 513.12,
    "y1": 83.52,
    "y2": 148.32
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/models-models2024/figures/10_1145-3640310_3674089-Table5-1.png"
}, {
  "caption": "Table 6: Comparison of ModelMate with other ML-based recommenders in the feature name recommendation task.",
  "captionBoundary": {
    "x1": 53.50199890136719,
    "x2": 295.646240234375,
    "y1": 259.6361389160156,
    "y2": 276.22601318359375
  },
  "figType": "Table",
  "imageText": ["ModelMate", "0.52", "0.64", "0.18", "0.25", "EcoreBert", "0.34", "0.47", "0.09", "0.13", "MemoRec", "0.72", "0.73", "0.10", "0.12", "KNN/Glove", "0.70", "0.75", "0.06", "0.08", "ModelSet", "MAR/GenMyModel", "MRR@5", "SR@5", "MRR@5", "SR@5"],
  "name": "6",
  "page": 8,
  "regionBoundary": {
    "x1": 78.72,
    "x2": 268.32,
    "y1": 186.23999999999998,
    "y2": 257.28
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/models-models2024/figures/10_1145-3640310_3674089-Table6-1.png"
}, {
  "caption": "Figure 2: Training and evaluation workflow of ModelMate.",
  "captionBoundary": {
    "x1": 187.697998046875,
    "x2": 424.3017883300781,
    "y1": 191.41810607910156,
    "y2": 197.04901123046875
  },
  "figType": "Figure",
  "imageText": ["Results", "no", "Is", "text-based", "dataset?", "Tokenize", "Generate", "text", "Duplicate", "removal", "Evaluation)", "Fine-tuning", "Model", "Pre-trained", "model", "test", "validation", "train", "dataset", "yes", "Deduplicated", "(tokenized)", "Dataset", "Textual", "dataset"],
  "name": "2",
  "page": 4,
  "regionBoundary": {
    "x1": 103.67999999999999,
    "x2": 508.32,
    "y1": 82.56,
    "y2": 178.07999999999998
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/models-models2024/figures/10_1145-3640310_3674089-Figure2-1.png"
}]