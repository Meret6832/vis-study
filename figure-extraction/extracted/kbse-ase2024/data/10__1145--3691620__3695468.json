[{
  "caption": "Table 3: Comparison results of thirteen detectors.",
  "captionBoundary": {
    "x1": 205.57200622558594,
    "x2": 406.12353515625,
    "y1": 85.72634887695312,
    "y2": 91.35699462890625
  },
  "figType": "Table",
  "imageText": ["WizardCoder-15B", "0.00", "24.06", "100.00", "6.12", "75.66", "82.72", "0.00", "4.80", "100.00", "6.02", "100.00", "0.00", "0.00", "5.20", "100.00", "CodeLlama-34B-Instruct", "0.12", "93.60", "99.18", "27.40", "43.08", "67.85", "11.27", "64.73", "83.25", "19.78", "78.38", "57.45", "34.52", "55.66", "54.38", "28.97", "78.08", "28.55", "28.33", "62.10", "4.86", "58.12", "22.94", "39.56", "3.76", "90.35", "46.93", "0.90", "98.97", "48.39", "16.00", "82.87", "Writer.com", "[19]", "GPT-3.5-Turbo", "WizardCoder-15B", "46.42", "41.99", "43.46", "99.06", "1.68", "1.48", "98.67", "1.77", "1.99", "64.69", "39.62", "38.44", "58.10", "38.99", "45.01", "CodeLlama-34B-Instruct", "96.72", "4.21", "4.57", "99.07", "1.63", "1.25", "99.13", "1.14", "1.42", "67.99", "39.61", "34.48", "65.68", "41.18", "31.09", "88.10", "88.67", "10.21", "21.71", "98.66", "1.80", "3.35", "71.20", "99.42", "3.26", "3.69", "60.19", "53.05", "29.85", "26.97", "80.53", "1.89", "Scribbr.com", "[11]", "GPT-3.5-Turbo", "WizardCoder-15B", "57.01", "37.33", "25.57", "88.42", "19.65", "8.57", "26.08", "3.48", "94.61", "57.39", "78.42", "7.41", "59.31", "68.25", "14.58", "CodeLlama-34B-Instruct", "98.55", "3.89", "5.12", "91.40", "13.02", "5.57", "48.11", "3.48", "90.84", "66.88", "51.66", "23.69", "70.74", "43.07", "24.46", "86.15", "94.31", "13.59", "8.46", "87.21", "20.16", "10.91", "54.42", "45.45", "3.48", "86.59", "57.76", "60.32", "28.78", "58.09", "40.88", "46.38", "Originality.ai", "[15]", "GPT-3.5-Turbo", "WizardCoder-15B", "31.21", "100.00", "21.00", "49.98", "100.00", "0.02", "50.00", "100.00", "0.00", "50.00", "100.00", "0.00", "50.00", "100.00", "0.00", "CodeLlama-34B-Instruct", "50.00", "100.00", "0.00", "50.00", "100.00", "0.00", "50.00", "100.00", "0.00", "50.00", "100.00", "0.00", "49.95", "100.00", "0.05", "46.83", "49.77", "100.00", "0.23", "50.00", "100.00", "0.00", "49.99", "50.00", "100.00", "0.00", "50.00", "100.00", "0.00", "50.00", "100.00", "0.00", "Grover", "[13]", "GPT-3.5-Turbo", "WizardCoder-15B", "35.09", "38.11", "91.72", "86.13", "5.89", "21.86", "25.62", "48.83", "99.93", "46.81", "6.51", "99.87", "51.20", "2.96", "94.65", "CodeLlama-34B-Instruct", "76.83", "21.09", "25.25", "92.88", "5.88", "8.37", "26.44", "48.83", "98.30", "50.72", "6.51", "92.06", "53.11", "3.01", "90.77", "76.41", "73.74", "21.09", "31.44", "93.79", "5.88", "6.54", "42.84", "31.37", "48.83", "88.43", "50.33", "7.62", "91.72", "49.97", "3.11", "96.94", "GPTZero.me", "[12]", "GPT-3.5-Turbo", "WizardCoder-15B", "66.49", "39.43", "25.11", "66.39", "57.23", "3.83", "50.22", "97.02", "2.48", "53.70", "87.54", "4.97", "52.01", "90.47", "5.40", "CodeLlama-34B-Instruct", "85.92", "29.46", "4.03", "68.26", "57.21", "0.48", "51.27", "96.95", "0.50", "54.76", "87.54", "2.95", "53.12", "90.47", "3.36", "71.42", "76.00", "37.88", "9.19", "65.43", "57.21", "2.11", "51.99", "51.14", "97.02", "0.64", "50.79", "95.24", "3.21", "50.90", "95.06", "3.16", "Crossplag.com", "[14]", "GPT-3.5-Turbo", "WizardCoder-15B", "55.90", "3.84", "76.44", "96.73", "6.91", "11.51", "92.21", "13.20", "17.32", "83.03", "27.22", "24.03", "71.01", "44.85", "24.16", "CodeLlama-34B-Instruct", "98.61", "3.48", "5.44", "98.78", "2.00", "5.44", "81.65", "20.72", "31.30", "78.84", "30.45", "28.11", "77.26", "36.09", "22.73", "90.02", "92.22", "12.72", "17.70", "97.89", "5.92", "8.63", "72.88", "54.36", "68.13", "15.40", "57.65", "57.07", "30.49", "59.91", "63.30", "19.62", "Fast-DetectGPT", "[24]", "GPT-3.5-Turbo", "WizardCoder-15B", "24.89", "63.63", "58.10", "29.63", "41.24", "74.70", "0.30", "100.00", "0.28", "50.54", "55.96", "35.41", "76.25", "13.91", "36.85", "CodeLlama-34B-Instruct", "29.75", "63.17", "57.64", "23.13", "64.94", "72.72", "0.29", "0.00", "99.93", "39.07", "97.89", "1.79", "73.10", "27.57", "32.87", "24.13", "19.37", "95.15", "26.26", "18.02", "97.82", "14.78", "36.51", "1.06", "0.00", "99.93", "39.39", "99.99", "0.01", "48.55", "67.99", "30.12", "MultiScale", "[65]", "GPT-3.5-Turbo", "WizardCoder-15B", "33.21", "26.12", "77.58", "92.11", "9.55", "18.69", "62.52", "25.41", "52.24", "50.36", "70.87", "27.91", "58.42", "26.30", "60.91", "CodeLlama-34B-Instruct", "91.38", "6.36", "15.69", "91.15", "10.63", "18.71", "62.30", "22.07", "54.93", "50.06", "67.17", "31.49", "56.79", "35.83", "50.51", "78.68", "74.53", "7.32", "45.56", "89.70", "10.73", "21.55", "55.64", "60.50", "41.23", "40.45", "50.02", "71.55", "27.47", "49.80", "47.04", "51.02", "MAGE", "[45]", "GPT-3.5-Turbo", "WizardCoder-15B", "42.80", "43.69", "46.52", "21.84", "91.00", "28.19", "33.69", "84.24", "9.23", "50.03", "73.30", "20.51", "67.93", "47.20", "23.60", "CodeLlama-34B-Instruct", "81.55", "27.26", "18.39", "30.86", "95.04", "3.20", "29.21", "95.46", "3.19", "45.33", "85.90", "12.00", "70.70", "36.39", "30.07", "44.81", "73.99", "25.21", "36.23", "17.83", "93.34", "22.94", "49.46", "45.31", "80.41", "11.43", "44.72", "99.90", "0.08", "58.22", "52.04", "34.00", "RADAR", "[38]", "GPT-3.5-Turbo", "WizardCoder-15B", "25.46", "73.79", "39.71", "93.66", "6.03", "24.10", "76.91", "2.34", "34.14", "47.87", "31.71", "68.04", "44.55", "99.90", "0.00", "CodeLlama-34B-Instruct", "88.69", "7.55", "24.57", "97.12", "3.05", "11.80", "69.29", "2.34", "40.38", "51.31", "27.58", "63.67", "46.77", "17.69", "77.68", "80.36", "82.45", "12.85", "29.55", "94.77", "5.93", "20.15", "57.02", "79.52", "5.75", "30.38", "49.53", "29.69", "65.62", "47.46", "9.33", "87.21", "ArguGPT", "[53]", "GPT-3.5-Turbo", "WizardCoder-15B", "13.85", "89.84", "34.13", "39.89", "19.65", "76.35", "0.13", "100.00", "0.00", "42.67", "99.98", "0.01", "48.19", "70.03", "24.31", "CodeLlama-34B-Instruct", "56.61", "22.55", "60.66", "27.13", "51.02", "71.42", "0.05", "100.00", "2.84", "38.06", "52.51", "65.49", "46.55", "90.42", "8.05", "34.80", "37.19", "7.14", "91.17", "34.13", "37.40", "70.73", "28.58", "0.31", "100.00", "3.90", "42.92", "56.21", "53.40", "38.31", "61.47", "50.82", "RoBERTa-QA", "[32]", "GPT-3.5-Turbo", "WizardCoder-15B", "5.78", "100.00", "27.45", "77.57", "27.10", "30.18", "62.11", "27.89", "52.59", "44.33", "0.00", "100.00", "48.26", "76.35", "22.22", "CodeLlama-34B-Instruct", "30.95", "0.00", "99.41", "74.82", "30.96", "30.30", "62.61", "29.10", "50.39", "47.06", "53.74", "49.27", "45.50", "96.53", "3.36", "47.98", "26.94", "0.00", "99.95", "71.82", "35.70", "30.32", "51.63", "54.90", "31.30", "59.90", "49.97", "77.43", "22.01", "49.94", "79.05", "19.16", "GPT2_Detector", "[1]", "GPT-3.5-Turbo", "Q&A-LLM", "Code2Doc-LLM", "CONCODE-LLM", "Doc2Code-LLM", "APPS-LLM", "Avg.(AUC)", "AUC", "FPR", "FNR", "AUC", "FPR", "FNR", "Avg.(AUC)", "AUC", "FPR", "FNR", "AUC", "FPR", "FNR", "AUC", "FPR", "FNR", "Detector", "Model", "NLCD-Test", "CCD-Test"],
  "name": "3",
  "page": 6,
  "regionBoundary": {
    "x1": 56.64,
    "x2": 555.36,
    "y1": 100.8,
    "y2": 413.28
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/kbse-ase2024/figures/10_1145-3691620_3695468-Table3-1.png"
}, {
  "caption": "Table 9: Robustness analysis of the fine-tuned models.",
  "captionBoundary": {
    "x1": 328.2139892578125,
    "x2": 547.6388549804688,
    "y1": 82.89236450195312,
    "y2": 88.52301025390625
  },
  "figType": "Table",
  "imageText": ["AddDeadCode", "1926", "0.52", "7", "0.00", "VarRename", "636", "0.17", "54", "0.04", "Hybrid", "2704", "0.73", "173", "0.12", "Composite-Code", "3729", "-", "1442", "-", "FuncAddLine", "2096", "0.56", "101", "0.07", "AugAssign", "1219", "0.33", "1", "0.00", "For2While", "693", "0.19", "1", "0.00", "Detector", "GPT-3.5-Turbo", "Human", "Num", "ùê∂ùëüùëéùë°ùëí", "Num", "ùêªùëüùëéùë°ùëí"],
  "name": "9",
  "page": 9,
  "regionBoundary": {
    "x1": 349.91999999999996,
    "x2": 527.04,
    "y1": 103.2,
    "y2": 211.2
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/kbse-ase2024/figures/10_1145-3691620_3695468-Table9-1.png"
}, {
  "caption": "Table 1: The details of the existing AIGC detectors.",
  "captionBoundary": {
    "x1": 203.12901306152344,
    "x2": 408.5670166015625,
    "y1": 85.72634887695312,
    "y2": 91.35699462890625
  },
  "figType": "Table",
  "imageText": ["Commercial", "Grover.Allenai", "[13]", "‚úì", "‚úì", "‚úì", "100", "chars", "to", "100k", "chars", "Compilatio.net", "[6]", "‚úì", "‚úì", "‚úì", "200", "chars", "to", "2k", "chars", "Contentatscale.ai", "[2]", "‚úì", "‚úì", "‚úì", "25", "words", "to", "25k", "chars", "CopyLeaks.com", "[4]", "‚úì", "‚úì", "‚úì", "‚úì", "150", "chars", "to", "25k", "chars", "Crossplag.com", "[14]", "‚úì", "‚úì", "‚úì", "<3k", "words", "GPTZero.me", "[12]", "‚úì", "‚úì", "‚úì", "‚úì", "‚úì", "‚úì", "250", "chars", "to", "5k", "chars", "Originality.ai", "[15]", "‚úì", "‚úì", "‚úì", "50", "words", "to", "300words", "Sapling.ai", "[16]", "‚úì", "‚úì", "‚úì", "‚úì", "‚úì", "50", "words", "to", "2k", "chars", "Scribbr.com", "[11]", "‚úì", "‚úì", "‚úì", "‚úì", "‚úì", "25", "words", "to", "500", "words", "Writefull.com", "[18]", "‚úì", "‚úì", "‚úì", "‚úì", "50", "words", "to", "2k", "words", "Writer.com", "[19]", "‚úì", "‚úì", "‚úì", "<1.5k", "chars", "Open-source", "GPT2-Detector", "[1]", "‚úì", "‚úì", "<512", "tokens", "DetectGPT", "[56]", "‚úì", "‚úì", "‚úì", "<512", "tokens", "RoBERTa-QA", "[32]", "‚úì", "‚úì", "‚úì", "<512", "tokens", "ArguGPT", "[53]", "‚úì", "‚úì", "‚úì", "‚úì", "‚úì", "<512", "tokens", "MAGE", "[45]", "‚úì", "‚úì", "‚úì", "‚úì", "‚úì", "<2048", "tokens", "RADAR", "[38]", "‚úì", "‚úì", "‚úì", "‚úì", "‚úì", "<512", "tokens", "FastDetectGPT", "[24]", "‚úì", "‚úì", "‚úì", "‚úì", "<512", "tokens", "Multiscale", "[65]", "‚úì", "‚úì", "‚úì", "‚úì", "‚úì", "<512", "tokens", "Detector", "Detectable", "Models", "Interfaces", "Input", "Length", "GPT-2", "GPT-3", "ChatGPT", "Llama", "Unknown", "Website", "API"],
  "name": "1",
  "page": 2,
  "regionBoundary": {
    "x1": 105.6,
    "x2": 506.4,
    "y1": 100.32,
    "y2": 300.0
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/kbse-ase2024/figures/10_1145-3691620_3695468-Table1-1.png"
}, {
  "caption": "Table 4: The AUC performance of different detectors on the Doc2Code-LLM testset in terms of code complexity.",
  "captionBoundary": {
    "x1": 79.81900024414062,
    "x2": 531.8667602539062,
    "y1": 85.72634887695312,
    "y2": 91.35699462890625
  },
  "figType": "Table",
  "imageText": ["Avg.", "49.64", "39.22", "51.09", "49.17", "45.50", "38.53", "57.67", "50.09", "46.81", "57.39", "51.14", "57.95", "Hard", "GPT-3.5-Turbo", "48.45", "48.77", "35.42", "53.63", "47.37", "43.19", "35.06", "59.00", "49.65", "47.44", "50.34", "52.73", "58.76", "WizardCoder-15B", "48.70", "48.94", "35.67", "53.35", "47.61", "44.67", "36.51", "58.19", "49.88", "47.38", "51.36", "52.31", "58.53", "CodeLlama-34B-Instruct", "48.80", "48.94", "35.74", "53.27", "47.14", "44.39", "36.62", "58.68", "49.93", "47.71", "50.85", "52.71", "59.57", "Easy", "GPT-3.5-Turbo", "50.82", "50.36", "48.58", "45.69", "51.36", "44.01", "40.55", "57.91", "50.77", "47.39", "64.52", "50.26", "58.40", "WizardCoder-15B", "50.74", "50.27", "48.06", "45.77", "51.33", "43.75", "40.20", "58.21", "50.68", "47.42", "64.63", "50.27", "58.30", "CodeLlama-34B-Instruct", "50.74", "50.37", "48.00", "46.12", "51.55", "43.63", "40.30", "58.13", "50.60", "47.19", "64.62", "50.22", "58.10", "Medium", "GPT-3.5-Turbo", "49.12", "49.83", "33.34", "54.19", "49.01", "48.76", "40.14", "56.02", "49.66", "45.37", "56.35", "50.40", "56.35", "WizardCoder-15B", "49.13", "49.60", "33.78", "54.11", "48.72", "48.97", "39.22", "56.09", "49.76", "45.54", "56.66", "50.59", "56.48", "CodeLlama-34B-Instruct", "49.15", "49.66", "34.33", "53.66", "48.42", "48.11", "38.21", "56.77", "49.87", "45.83", "57.15", "50.77", "57.04", "Complexity", "Model", "Avg.", "GPT2_Detector", "RoBETa-QA", "ArguGPT", "MAGE", "RADAR", "MultiScale", "Fast-DetectGPT", "GPTZero.me", "Writer.com", "Scribbr.com", "Crossplag.com", "Originality.ai"],
  "name": "4",
  "page": 7,
  "regionBoundary": {
    "x1": 66.72,
    "x2": 545.28,
    "y1": 100.8,
    "y2": 179.04
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/kbse-ase2024/figures/10_1145-3691620_3695468-Table4-1.png"
}, {
  "caption": "Table 5: The AUC performance of different detectors on the Doc2Code-LLM testset in terms of code length.",
  "captionBoundary": {
    "x1": 89.28800201416016,
    "x2": 522.3994750976562,
    "y1": 192.25637817382812,
    "y2": 197.88702392578125
  },
  "figType": "Table",
  "imageText": ["Avg.", "44.42", "39.85", "44.04", "44.55", "40.64", "37.43", "49.67", "44.65", "42.51", "51.67", "45.05", "50.43", "Long[197+]", "GPT-3.5-Turbo", "33.44", "33.15", "31.66", "33.78", "32.86", "32.11", "31.29", "35.47", "33.36", "34.21", "34.18", "34.01", "35.19", "WizardCoder-15B", "50.39", "49.03", "37.54", "49.40", "47.73", "41.59", "33.90", "63.23", "50.85", "50.15", "62.80", "52.82", "65.65", "CodeLlama-34B-Instruct", "49.96", "49.15", "38.40", "49.69", "48.41", "41.97", "34.59", "61.48", "50.51", "49.02", "61.17", "52.14", "62.94", "Short[0-72]]", "GPT-3.5-Turbo", "33.69", "33.46", "36.26", "33.41", "34.12", "36.09", "36.55", "31.40", "33.33", "32.92", "32.33", "32.90", "31.56", "WizardCoder-15B", "50.89", "50.87", "50.08", "49.49", "52.90", "48.42", "46.70", "53.50", "49.84", "45.21", "60.04", "49.81", "53.82", "CodeLlama-34B-Instruct", "50.68", "51.08", "49.36", "49.91", "52.87", "47.94", "46.17", "53.56", "49.78", "44.64", "59.20", "49.81", "53.85", "Medium[72-197]", "GPT-3.5-Turbo", "32.87", "33.39", "32.08", "32.81", "33.02", "31.80", "32.16", "33.13", "33.32", "32.88", "33.49", "33.09", "33.25", "WizardCoder-15B", "49.66", "49.87", "41.77", "49.14", "49.64", "42.82", "37.64", "57.87", "50.40", "46.87", "60.75", "50.44", "58.69", "CodeLlama-34B-Instruct", "49.60", "49.81", "41.47", "48.69", "49.40", "43.06", "37.86", "57.39", "50.44", "46.70", "61.04", "50.41", "58.89", "Length", "Model", "Avg.", "GPT2_Detector", "RoBETa-QA", "ArguGPT", "MAGE", "RADAR", "MultiScale", "Fast-DetectGPT", "GPTZero.me", "Writer.com", "Scribbr.com", "Crossplag.com", "Originality.ai"],
  "name": "5",
  "page": 7,
  "regionBoundary": {
    "x1": 66.72,
    "x2": 545.28,
    "y1": 206.88,
    "y2": 284.15999999999997
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/kbse-ase2024/figures/10_1145-3691620_3695468-Table5-1.png"
}, {
  "caption": "Table 6: The AUC performance of different detectors on the Doc2Code-LLM testset on 6 programming languages.",
  "captionBoundary": {
    "x1": 77.01699829101562,
    "x2": 534.66845703125,
    "y1": 297.12835693359375,
    "y2": 302.7590026855469
  },
  "figType": "Table",
  "imageText": ["Avg.", "49.58", "48.45", "48.81", "49.21", "42.68", "37.27", "57.59", "50.15", "45.96", "61.47", "50.02", "58.54", "Go", "47.95", "46.60", "17.50", "39.93", "48.86", "58.61", "48.76", "59.82", "50.06", "48.21", "53.24", "52.32", "51.51", "Java", "51.75", "50.31", "33.78", "59.94", "52.37", "47.12", "36.36", "63.55", "51.82", "47.96", "67.58", "50.42", "59.80", "Javascript", "51.56", "48.56", "53.30", "51.58", "45.73", "40.47", "27.23", "55.17", "49.61", "47.67", "80.91", "51.21", "67.29", "PHP", "50.74", "49.36", "53.29", "38.00", "50.75", "40.48", "38.21", "59.58", "50.79", "49.80", "68.13", "50.55", "59.99", "Python", "47.88", "52.83", "45.54", "58.17", "49.52", "41.79", "39.91", "57.38", "48.17", "41.70", "37.03", "50.76", "51.80", "Ruby", "49.98", "49.80", "87.28", "45.23", "48.04", "27.59", "33.14", "50.06", "50.47", "40.45", "61.95", "44.88", "60.87", "Language", "Avg.", "GPT2_Detector", "RoBETa-QA", "ArguGPT", "MAGE", "RADAR", "MultiScale", "Fast-DetectGPT", "GPTZero.me", "Writer.com", "Scribbr.com", "Crossplag.com", "Originality.ai"],
  "name": "6",
  "page": 7,
  "regionBoundary": {
    "x1": 66.72,
    "x2": 545.28,
    "y1": 312.0,
    "y2": 381.12
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/kbse-ase2024/figures/10_1145-3691620_3695468-Table6-1.png"
}, {
  "caption": "Table 7: Results of fine-tuned models on different NLCDTrain datasets.",
  "captionBoundary": {
    "x1": 53.35900115966797,
    "x2": 295.0025634765625,
    "y1": 85.72634887695312,
    "y2": 102.31597900390625
  },
  "figType": "Table",
  "imageText": ["Avg.", "0.77", "0.25", "0.28", "0.73", "0.23", "0.33", "Q&A-LLM", "0.89", "0.21", "0.18", "0.42", "0.34", "0.74", "Code2Doc-LLM", "0.43", "0.52", "0.65", "1.00", "0.00", "0.01", "Composite-NL", "1.00", "0.01", "0.01", "0.78", "0.34", "0.24", "MLP", "Avg.", "0.95", "0.03", "0.14", "0.90", "0.33", "0.00", "RoBERTa-QA", "Q&A-LLM", "1.00", "0.", "00", "0.00", "0.69", "0.99", "0.00", "Code2Doc-LLM", "0.84", "0.08", "0.41", "1.00", "0.00", "0.00", "Composite-NL", "1.00", "0.00", "0.00", "1.00", "0.00", "0.00", "Unfined-tuned", "RoBERTa-QA", "0.37", "0.07", "0.91", "0.34", "0.37", "0.71", "Q&A-LLM", "Code2Doc-LLM", "AUC", "FPR", "FNR", "AUC", "FPR", "FNR", "Detector", "NLCD-Test"],
  "name": "7",
  "page": 8,
  "regionBoundary": {
    "x1": 54.72,
    "x2": 293.28,
    "y1": 110.88,
    "y2": 225.12
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/kbse-ase2024/figures/10_1145-3691620_3695468-Table7-1.png"
}, {
  "caption": "Table 8: Results of fine-tuned models on different CCD-Train datasets.",
  "captionBoundary": {
    "x1": 53.50199890136719,
    "x2": 294.0462951660156,
    "y1": 248.03836059570312,
    "y2": 264.62799072265625
  },
  "figType": "Table",
  "imageText": ["Avg.", "0.73", "0.14", "0.38", "0.68", "0.40", "0.30", "0.60", "0.48", "0.37", "APPS-LLM", "0.29", "0.00", "1.00", "0.51", "0.13", "0.83", "0.73", "0.38", "0.29", "CONCODE-LLM", "0.99", "0.02", "0.08", "0.44", "0.98", "0.02", "0.43", "0.68", "0.40", "Doc2Code-LLM", "0.66", "0.48", "0.34", "0.89", "0.22", "0.17", "0.56", "0.45", "0.47", "Composite-Code", "0.98", "0.06", "0.13", "0.89", "0.24", "0.16", "0.68", "0.41", "0.32", "MLP", "Avg.", "0.86", "0.00", "0.49", "0.78", "0.37", "0.11", "0.71", "0.70", "0.02", "RoBERTa-QA", "APPS-LLM", "0.50", "0.00", "1.00", "0.61", "0.39", "0.43", "0.94", "0.49", "0.00", "CONCODE-LLM", "1.00", "0.00", "0.00", "0.53", "0.99", "0.00", "0.52", "1.00", "0.00", "Doc2Code-LLM", "0.94", "0.00", "0.94", "1.00", "0.04", "0.01", "0.56", "0.80", "0.06", "Composite-Code", "1.00", "0.00", "0.00", "1.00", "0.04", "0.01", "0.84", "0.53", "0.01", "Unfined-tuned", "RoBERTa-QA", "0.03", "1.00", "0.04", "0.43", "0.56", "0.53", "0.38", "0.62", "0.51", "CONCODE-LLM", "Doc2Code-LLM", "APPS-LLM", "AUC", "FPR", "FNR", "AUC", "FPR", "FNR", "AUC", "FPR", "FNR", "Detector", "CCD-Test"],
  "name": "8",
  "page": 8,
  "regionBoundary": {
    "x1": 54.72,
    "x2": 293.28,
    "y1": 278.88,
    "y2": 383.03999999999996
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/kbse-ase2024/figures/10_1145-3691620_3695468-Table8-1.png"
}, {
  "caption": "Table 2: The statistics of the collected data for each selected large language model.",
  "captionBoundary": {
    "x1": 139.75,
    "x2": 471.9403076171875,
    "y1": 85.72634887695312,
    "y2": 91.35699462890625
  },
  "figType": "Table",
  "imageText": ["Total", "150K", "1M", "1M", "66K", "8.7K", "Train", "148K", "908K", "904K", "65K", "5K", "Test", "2K", "97K", "96.6K", "1.4K", "3.7K", "Split", "NLCD", "CCD", "Q&A-LLM", "Code2Doc-LLM", "Doc2Code-LLM", "CONCODE-LLM", "APPS-LLM"],
  "name": "2",
  "page": 4,
  "regionBoundary": {
    "x1": 180.95999999999998,
    "x2": 431.03999999999996,
    "y1": 94.56,
    "y2": 147.35999999999999
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/kbse-ase2024/figures/10_1145-3691620_3695468-Table2-1.png"
}]