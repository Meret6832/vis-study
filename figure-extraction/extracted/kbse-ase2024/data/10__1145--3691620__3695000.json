[{
  "caption": "Table 3: Results on all APPS test sets (Solved Problems) on three topics of varying difficulty. CodeGen (350M), after finetuning, serves as the base generation model. The red percentage indicates the relative improvement of the metric after ranking compared to that before ranking.",
  "captionBoundary": {
    "x1": 53.50199890136719,
    "x2": 295.64263916015625,
    "y1": 374.1888122558594,
    "y2": 424.0400085449219
  },
  "figType": "Table",
  "imageText": ["CodeRanker*", "10.34", "48.4%", "15.87", "22.3%", "31.73", "29.4%Inter", "RankEF", "14.90", "113.8%", "21.63", "66.6%", "36.06", "47.1%", "Random", "2.72", "5.44", "13.61", "CodeRanker*", "3.06", "12.5%", "6.12", "12.5%", "15.31", "12.5%Comp", "RankEF", "5.10", "87.5%", "9.80", "80.1%", "21.43", "57.5%", "RankEF", "18.52", "118.7%", "26.99", "64.6%", "41.80", "58.0%", "Random", "6.97", "12.98", "24.52", "Random", "8.47", "16.40", "26.46", "CodeRanker*", "16.40", "93.6%", "23.81", "45.2%", "38.10", "44.0%Intro", "Difficulty", "level", "Method", "Pass@1", "Pass@2", "Pass@5"],
  "name": "3",
  "page": 6,
  "regionBoundary": {
    "x1": 54.72,
    "x2": 295.2,
    "y1": 429.59999999999997,
    "y2": 517.4399999999999
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/kbse-ase2024/figures/10_1145-3691620_3695000-Table3-1.png"
}, {
  "caption": "Table 1: Results on APPS validation dataset.",
  "captionBoundary": {
    "x1": 217.26901245117188,
    "x2": 394.42828369140625,
    "y1": 85.34080505371094,
    "y2": 91.35699462890625
  },
  "figType": "Table",
  "imageText": ["PyCodeGPT", "110M", "4.52", "6.99", "9.53", "7.02", "10.85", "13.04", "12.04", "16.08", "19.23", "StarCoder", "164M", "6.41", "9.86", "12.04", "10.11", "13.23", "15.34", "17.22", "19.76", "21.88", "CodeGen", "350M", "6.69", "11.28", "15.91", "11.87", "15.51", "19.77", "19.57", "24.66", "28.64", "CodeT5+", "770M", "12.54", "16.42", "18.46", "18.42", "22.13", "23.87", "27.76", "31.08", "33.93", "GPT-Neo", "1.3B", "6.06", "9.39", "11.54", "9.88", "12.87", "15.22", "15.12", "19.04", "22.07", "CodeGen", "2B", "15.72", "19.23", "25.08", "24.41", "27.92", "31.61", "34.39", "37.29", "41.14", "CodeLlama", "7B", "18.56", "25.10", "28.93", "29.26", "34.49", "38.13", "43.48", "48.84", "53.68", "Pass@1", "Pass@2", "Pass@5Model", "para", "Random", "CodeRanker*", "RankEF", "Random", "CodeRanker*", "RankEF", "Random", "CodeRanker*", "RankEF"],
  "name": "1",
  "page": 6,
  "regionBoundary": {
    "x1": 55.68,
    "x2": 556.3199999999999,
    "y1": 96.96,
    "y2": 198.23999999999998
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/kbse-ase2024/figures/10_1145-3691620_3695000-Table1-1.png"
}, {
  "caption": "Table 2: Results on APPS Test Dataset (Solved Problems). StarCoder (15B) and GPT-3.5, are not fine-tuned on the APPS dataset. Instead, they generate code candidates in a one-shot manner (with GPT-3.5 using only the most difficult 1,000 problems in the test set) and utilize rankers trained on samples from other generative models (second row). ‚ÄòStarCoder-Best‚Äô and ‚ÄòGPT-3.5Turbo-Best‚Äô signify the peak performance achieved by these diverse rankers.",
  "captionBoundary": {
    "x1": 53.0629997253418,
    "x2": 559.7890014648438,
    "y1": 203.81578063964844,
    "y2": 242.7080078125
  },
  "figType": "Table",
  "imageText": ["StarCoder-Best", "15B", "4.90", "9.95", "16.60", "8.11", "20.03", "29.60", "17.35", "38.26", "50.19", "GPT-3.5-Turbo-Best", "-", "4.26", "8.51", "10.11", "9.04", "13.83", "19.15", "28.72", "31.41", "38.30", "Pass@1", "Pass@2", "Pass@5Model", "para", "Random", "CodeRanker*", "RankEF", "Random", "CodeRanker*", "RankEF", "Random", "CodeRanker*", "RankEF", "PyCodeGPT", "110M", "6.07", "12.14", "18.85", "8.94", "17.57", "25.56", "19.81", "31.31", "40.26", "StarCoder", "164M", "6.22", "11.95", "13.21", "13.27", "16.62", "19.88", "26.23", "30.57", "34.20", "CodeGen", "350M", "8.07", "12.08", "15.47", "13.67", "18.39", "25.34", "24.44", "32.73", "38.16", "CodeT5+", "770M", "12.42", "15.82", "19.76", "21.05", "25.32", "31.29", "35.06", "39.52", "45.18", "GPT-Neo", "1.3B", "6.82", "9.49", "11.45", "11.67", "14.68", "17.21", "22.67", "25.63", "29.88", "CodeGen", "2B", "10.48", "13.96", "17.50", "17.66", "20.69", "26.62", "32.84", "33.93", "41.93", "CodeLlama", "7B", "15.03", "18.02", "23.12", "24.47", "26.59", "33.04", "38.25", "43.26", "47.98"],
  "name": "2",
  "page": 6,
  "regionBoundary": {
    "x1": 54.72,
    "x2": 557.28,
    "y1": 248.64,
    "y2": 366.24
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/kbse-ase2024/figures/10_1145-3691620_3695000-Table2-1.png"
}, {
  "caption": "Figure 4: Results of RankEF‚Äôs generalized capabilities on datasets with different models (CodeRanker* is trained on the same model data).",
  "captionBoundary": {
    "x1": 53.79800033569336,
    "x2": 294.03839111328125,
    "y1": 243.75181579589844,
    "y2": 271.68597412109375
  },
  "figType": "Figure",
  "imageText": ["1.0", "0.9", "0.8", "0.7", "od", "el", "er", "M", "Ra", "nk", "CodeRanker*", "D.CodeGen", "2B", "D.GPT", "Neo", "D.CodeT5", "+", "D.CodeGen", "350M", "D.StarCoder", "D.PyCodeGPT", "Code", "Gen.", "Model", "-2", "B", "G", "en", "Co", "de", "-N", "eo", "G", "PT", "T5", "+", "Co", "de", "M", "-3", "50", "G", "en", "Co", "de", "r", "Co", "de", "St", "ar", "PT", "de", "G", "Py", "Co"],
  "name": "4",
  "page": 9,
  "regionBoundary": {
    "x1": 73.44,
    "x2": 263.52,
    "y1": 87.36,
    "y2": 235.2
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/kbse-ase2024/figures/10_1145-3691620_3695000-Figure4-1.png"
}, {
  "caption": "Figure 1: An example after being ranked by CodeRanker.",
  "captionBoundary": {
    "x1": 58.57400131225586,
    "x2": 289.26019287109375,
    "y1": 467.6128234863281,
    "y2": 473.6289978027344
  },
  "figType": "Figure",
  "imageText": ["Figure", "3:", "Prompt", "Example"],
  "name": "1",
  "page": 2,
  "regionBoundary": {
    "x1": 63.839999999999996,
    "x2": 292.32,
    "y1": 444.47999999999996,
    "y2": 460.32
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/kbse-ase2024/figures/10_1145-3691620_3695000-Figure1-1.png"
}, {
  "caption": "Table 4: Results of the transfer capabilities on MBPP. ‚ÄòFinetuned on APPS‚Äô refers to using base generation models fine-tuned on APPS to sample candidate code, while ‚ÄòNon-fine-tuned‚Äô refers to using base models that have not been fine-tuned on APPS.",
  "captionBoundary": {
    "x1": 53.46699905395508,
    "x2": 558.1826171875,
    "y1": 85.34080505371094,
    "y2": 102.31597900390625
  },
  "figType": "Table",
  "imageText": ["Pass@1", "Pass@2", "Pass@5Model", "para", "Random", "CodeRanker*", "RankEF", "Random", "CodeRanker*", "RankEF", "Random", "CodeRanker*", "RankEF", "Fine-tuned", "on", "APPS", "PyCodeGPT", "110M", "5.84", "8.10", "13.80", "9.92", "12.96", "17.98", "16.20", "19.23", "24.00", "StarCoder", "164M", "6.77", "8.52", "13.80", "11.98", "14.47", "18.00", "18.22", "20.02", "24.29", "CodeGen", "350M", "13.94", "16.24", "19.12", "20.12", "22.48", "24.88", "29.00", "31.24", "33.63", "CodeT5+", "770M", "18.28", "21.44", "24.28", "25.94", "27.01", "30.02", "35.60", "38.42", "40.01", "GPT-Neo", "1.3B", "6.42", "10.04", "11.68", "11.84", "13.70", "16.20", "18.41", "19.20", "21.02", "CodeGen", "2B", "26.45", "29.12", "31.85", "36.36", "38.03", "39.56", "46.80", "47.20", "49.47", "CodeLlama", "7B", "38.40", "40.02", "41.98", "46.30", "48.38", "49.74", "58.80", "58.91", "59.72", "Non-fine-tuned", "CodeT5+", "770M", "12.00", "14.72", "16.60", "18.60", "21.10", "22.92", "28.00", "31.00", "32.20", "CodeGen", "2B", "24.96", "28.95", "30.78", "33.19", "35.01", "36.27", "43.58", "44.06", "45.66", "CodeLlama", "7B", "34.00", "35.65", "38.36", "44.86", "45.33", "46.92", "56.33", "58.01", "59.11"],
  "name": "4",
  "page": 7,
  "regionBoundary": {
    "x1": 55.68,
    "x2": 556.3199999999999,
    "y1": 108.0,
    "y2": 264.0
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/kbse-ase2024/figures/10_1145-3691620_3695000-Table4-1.png"
}, {
  "caption": "Table 5: Results of the transfer capabilities on HumanEval.",
  "captionBoundary": {
    "x1": 186.58200073242188,
    "x2": 425.1134033203125,
    "y1": 268.96783447265625,
    "y2": 274.9840087890625
  },
  "figType": "Table",
  "imageText": ["Fine-tuned", "on", "APPS", "PyCodeGPT", "110M", "4.76", "6.10", "8.17", "7.26", "8.72", "10.67", "10.98", "12.20", "13.41", "StarCoder", "164M", "6.34", "7.20", "8.79", "7.99", "8.78", "10.26", "10.37", "11.02", "12.20", "CodeGen", "350M", "6.71", "7.20", "9.39", "8.78", "10.30", "11.46", "10.98", "13.41", "15.24", "CodeT5+", "770M", "10.89", "12.89", "13.54", "14.24", "15.84", "16.59", "19.51", "21.34", "23.07", "GPT-Neo", "1.3B", "4.76", "6.08", "7.21", "6.34", "7.88", "8.78", "7.92", "10.98", "12.20", "CodeGen", "2B", "14.63", "17.32", "19.39", "20.06", "22.99", "24.94", "27.44", "32.93", "34.76", "CodeLlama", "7B", "23.29", "25.90", "29.39", "32.20", "34.07", "37.99", "45.12", "44.46", "48.17", "Non-fine-tuned", "CodeT5+", "770M", "11.34", "12.56", "14.63", "15.61", "17.11", "19.26", "21.34", "23.43", "25.00", "CodeGen", "2B", "17.80", "19.63", "22.86", "24.18", "25.11", "28.78", "32.53", "34.21", "36.59", "CodeLlama", "7B", "25.00", "27.37", "30.49", "34.69", "36.27", "38.92", "48.17", "47.63", "51.27", "Pass@1", "Pass@2", "Pass@5Model", "para", "Random", "CodeRanker*", "RankEF", "Random", "CodeRanker*", "RankEF", "Random", "CodeRanker*", "RankEF"],
  "name": "5",
  "page": 7,
  "regionBoundary": {
    "x1": 55.68,
    "x2": 556.3199999999999,
    "y1": 280.8,
    "y2": 436.32
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/kbse-ase2024/figures/10_1145-3691620_3695000-Table5-1.png"
}, {
  "caption": "Table 7: Results of different multi-task training methods on APPS, where ùëü represents the number of rounds of RankEFINF. CodeGen (2B), after fine-tuning, serves as the base generation model.",
  "captionBoundary": {
    "x1": 53.46699905395508,
    "x2": 295.6449279785156,
    "y1": 179.51683044433594,
    "y2": 218.40997314453125
  },
  "figType": "Table",
  "imageText": ["ùëü=4", "17.89", "26.58", "35.12", "13.97", "21.97", "35.76", "ùëü=1", "17.73", "26.25", "33.95", "13.38", "21.37", "32.69", "ùëü=2", "18.23", "27.41", "36.79", "13.24", "21.79", "36.28", "ùëü=3", "19.76", "28.03", "37.95", "15.90", "23.86", "37.10RankEF-INF", "CodeRanker*", "19.23", "27.92", "37.29", "13.96", "20.69", "33.93", "RankEF-Hard", "25.08", "31.61", "41.14", "17.50", "26.62", "41.93", "RankEF-Soft", "20.12", "28.59", "38.79", "16.14", "23.86", "38.07", "Val", "Test", "(Solved", "Problems)Methods", "Pass@1", "Pass@2", "Pass@5", "Pass@1", "Pass@2", "Pass@5", "Random", "15.72", "24.41", "34.39", "10.48", "17.66", "32.84"],
  "name": "7",
  "page": 8,
  "regionBoundary": {
    "x1": 54.72,
    "x2": 295.2,
    "y1": 223.67999999999998,
    "y2": 312.0
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/kbse-ase2024/figures/10_1145-3691620_3695000-Table7-1.png"
}, {
  "caption": "Table 8: Results of ablation experiments with different parameter weights on APPS. CodeGen (2B), after fine-tuning, serves as the base generation model.",
  "captionBoundary": {
    "x1": 53.50199890136719,
    "x2": 295.6424865722656,
    "y1": 321.3558349609375,
    "y2": 349.28900146484375
  },
  "figType": "Table",
  "imageText": ["0", "(CodeRanker)", "19.23", "27.92", "37.29", "13.96", "20.69", "33.93", "0.1", "17.89", "24.25", "34.95", "14.62", "20.82", "36.00", "0.3", "19.40", "25.59", "35.28", "16.28", "23.03", "38.43", "0.5", "18.23", "25.75", "36.96", "15.59", "24.00", "38.62", "0.7", "21.40", "27.42", "38.79", "17.03", "26.20", "40.66", "0.9", "25.08", "31.61", "41.14", "17.50", "26.62", "41.93", "1", "17.77", "24.02", "33.29", "13.25", "20.42", "34.01", "Task‚Äôs", "Weight", "Val", "Test", "(Solved", "Problems)", "ùúÜ", "Pass@1", "Pass@2", "Pass@5", "Pass@1", "Pass@2", "Pass@5"],
  "name": "8",
  "page": 8,
  "regionBoundary": {
    "x1": 54.72,
    "x2": 295.2,
    "y1": 354.71999999999997,
    "y2": 438.24
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/kbse-ase2024/figures/10_1145-3691620_3695000-Table8-1.png"
}, {
  "caption": "Table 6: Results on comparing with other non-executive code ranking methods. Where ‚ÄòRandom‚Äô stands for no ranking method, ‚ÄòCoder‚Äô is the method proposed by Chen et al. [6], and the rest of the methods are proposed by Zhang et al. [31].",
  "captionBoundary": {
    "x1": 53.117000579833984,
    "x2": 559.2721557617188,
    "y1": 85.34080505371094,
    "y2": 102.31597900390625
  },
  "figType": "Table",
  "imageText": ["MBPP", "Reported", "in", "[31]", "24.10", "28.40", "28.90", "30.50", "27.90", "29.30", "-", "Method", "Random", "Reviewer", "Coder", "Coder-Reviewer", "N.Coder", "N.Coder-Reviewer", "RankEF", "APPS", "10.48", "9.10", "10.34", "11.03", "7.44", "7.59", "17.50", "Our", "Results", "24.96", "-", "-", "-", "-", "-", "30.78"],
  "name": "6",
  "page": 8,
  "regionBoundary": {
    "x1": 65.75999999999999,
    "x2": 546.24,
    "y1": 108.0,
    "y2": 172.32
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/kbse-ase2024/figures/10_1145-3691620_3695000-Table6-1.png"
}]