[{
  "caption": "Table III F1-score of existing approaches on SATDs from different language projects.",
  "captionBoundary": {
    "x1": 60.34063720703125,
    "x2": 295.6536865234375,
    "y1": 231.22222900390625,
    "y2": 243.1793212890625
  },
  "figType": "Table",
  "imageText": ["Dataset-Dockerﬁle", "0.273", "0.869", "0.848", "0.759", "0.880", "Dataset-Python", "0.156", "0.957", "0.954", "0.956", "0.965", "Dataset-XML", "0.248", "0.802", "0.883", "0.895", "0.931", "Average", "0.226", "0.876", "0.895", "0.870", "0.925", "Average-Change", "(-8.5%)", "(+17.3%)", "(+17.6%)", "(+22.5%)", "(+10.9%)", "Dataset-M", "(baseline", "metric)", "0.247", "0.747", "0.761", "0.710", "0.834", "Pattern", "MAT", "NLP", "TM", "BERT", "Dataset", "Approach"],
  "name": "III",
  "page": 5,
  "regionBoundary": {
    "x1": 61.919999999999995,
    "x2": 294.24,
    "y1": 253.92,
    "y2": 328.32
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/wcre-saner2024/figures/10_1109-SANER60148_2024_00087-TableIII-1.png"
}, {
  "caption": "Table IV F1-score of existing approaches on SATDs across software artifacts.",
  "captionBoundary": {
    "x1": 327.6684875488281,
    "x2": 537.9212036132812,
    "y1": 305.0404052734375,
    "y2": 316.9974670410156
  },
  "figType": "Table",
  "imageText": ["Dataset-Issue", "0.031", "0.024", "0.242", "0.291", "0.244", "Dataset-PR", "0.030", "0.032", "0.369", "0.394", "0.385", "Dataset-Commits", "0.008", "0.024", "0.145", "0.287", "0.164", "Average", "0.023", "0.027", "0.252", "0.324", "0.264", "Average-Change", "(-90.7%)", "(-96.4%)", "(-66.9%)", "(-54.4%)", "(-68.3%)", "Dataset-M", "(baseline", "metric)", "0.247", "0.747", "0.761", "0.710", "0.834", "Pattern", "MAT", "NLP", "TM", "BERT", "Dataset", "Approach"],
  "name": "IV",
  "page": 5,
  "regionBoundary": {
    "x1": 315.84,
    "x2": 549.12,
    "y1": 323.52,
    "y2": 399.36
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/wcre-saner2024/figures/10_1109-SANER60148_2024_00087-TableIV-1.png"
}, {
  "caption": "Table I SATD Samples from four different artifacts.",
  "captionBoundary": {
    "x1": 364.1287536621094,
    "x2": 499.9419250488281,
    "y1": 181.23590087890625,
    "y2": 193.1929931640625
  },
  "figType": "Table",
  "imageText": ["Commit", "Messages", "“Removing", "unused", "dependency", "and", "changing", "de-", "fault", "daemon", "port", "to", "9090.", "Fixes", "#300”", "From", "[attic-apex-malhar-commit-01b162]", "Pull", "Requests", "“Is", "this", "the", "implementation", "class?", "If", "so", "can", "we", "use", "‘class’", "instead", "of", "type", "to", "be", "more", "explicit?”", "From", "[incubator-heron-pull-1820]", "Issue", "Trackers", "“This", "method", "is", "not", "speciﬁc", "to", "TaskTracker,", "i.e.,", "it", "should", "work", "ﬁne", "with", "LocalRunner", "too,", "right?", "So", "there", "ought", "to", "be", "a", "better", "place", "to", "put", "it.”", "From", "[hadoop-issue-1251]"],
  "name": "I",
  "page": 1,
  "regionBoundary": {
    "x1": 313.92,
    "x2": 551.04,
    "y1": 194.4,
    "y2": 295.2
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/wcre-saner2024/figures/10_1109-SANER60148_2024_00087-TableI-1.png"
}, {
  "caption": "Fig. 1. An example of the four existence cycles of SATD. II. SATD ACROSS PROGRAMMING LANGUAGES AND SOFTWARE ARTIFACTS",
  "captionBoundary": {
    "x1": 327.5712890625,
    "x2": 536.4932861328125,
    "y1": 454.5043029785156,
    "y2": 482.3067626953125
  },
  "figType": "Figure",
  "imageText": ["Code", "Comments", "“//", "TODO:", "This", "method", "doesn’t", "appear", "to", "be", "used.”", "From", "[jmeter-code-comment]"],
  "name": "1",
  "page": 1,
  "regionBoundary": {
    "x1": 313.92,
    "x2": 551.04,
    "y1": 298.08,
    "y2": 445.44
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/wcre-saner2024/figures/10_1109-SANER60148_2024_00087-Figure1-1.png"
}, {
  "caption": "Table VIII The list of selected real-world popular software projects.",
  "captionBoundary": {
    "x1": 220.4825439453125,
    "x2": 395.3509216308594,
    "y1": 74.58831787109375,
    "y2": 86.54541015625
  },
  "figType": "Table",
  "imageText": ["Average", "-", "119.6k", "2036", "4123", "420", "10.2", "Angular", "A", "popular", "framework", "for", "building", "web", "applications.", "87.4k", "1697", "1978", "120", "6.1", "Bootstrap", "A", "popular", "front-end", "development", "framework.", "163k", "1358", "2115", "310", "14.7", "Numpy", "The", "fundamental", "package", "for", "scientiﬁc", "computing", "with", "Python.", "23.2k", "1465", "1779", "337", "18.9", "Pytorch", "A", "popular", "open-source", "machine", "learning", "framework.", "65.1k", "2731", "8383", "765", "9.1", "React", "A", "JavaScript", "library", "for", "building", "user", "interfaces.", "206k", "1615", "716", "203", "28.4", "Tensorﬂow", "An", "end-to-end", "open", "source", "platform", "for", "machine", "learning.", "173k", "3353", "9764", "785", "8.0", "Project", "Description", "Stars", "Contributions", "#Changelog", "Items", "#SATD", "%", "of", "SATD"],
  "name": "VIII",
  "page": 9,
  "regionBoundary": {
    "x1": 67.67999999999999,
    "x2": 545.28,
    "y1": 88.8,
    "y2": 169.44
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/wcre-saner2024/figures/10_1109-SANER60148_2024_00087-TableVIII-1.png"
}, {
  "caption": "Table V The performance of our approach MT-BERT-SATD over MTM scenario.",
  "captionBoundary": {
    "x1": 321.71875,
    "x2": 543.5166015625,
    "y1": 370.9480285644531,
    "y2": 382.90509033203125
  },
  "figType": "Table",
  "imageText": ["Precision", "Recall", "F1-score", "Dataset", "Metrics"],
  "name": "V",
  "page": 7,
  "regionBoundary": {
    "x1": 328.8,
    "x2": 536.16,
    "y1": 389.28,
    "y2": 419.03999999999996
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/wcre-saner2024/figures/10_1109-SANER60148_2024_00087-TableV-1.png"
}, {
  "caption": "Table V presents the precision, recall, and F1-score metrics of MT-BERT-SATD for identifying SATDs across software artifacts simultaneously. The best and worst performance values are highlighted in bold and underlined, respectively. Our approach achieves an average F1-score of 71.2% for identifying SATDs from four different software artifacts, with the highest F1-score of 85.9% obtained for SATDs from code comments. However, the performance of SATD identification for the other three artifacts is slightly lower, with an average F1-score of 66.3%. Indeed, this phenomenon can be easily comprehended since SATDs in code comments are often accompanied by apparent prior knowledge, such as the usage of keywords like “TODO” and “FIXME”. These prior knowledge cues facilitate the identification of SATDs in code comments. However, the other three artifacts of SATD do not have such explicit prior knowledge. Specifically, OSS developers may report urgent SATDs or discuss SATDs in issue trackers without the above mentioned keywords [29], [30]. These discussions and reports can vary depending on the project and the urgency of the",
  "captionBoundary": {
    "x1": 314.61968994140625,
    "x2": 550.6219482421875,
    "y1": 492.27716064453125,
    "y2": 698.9677124023438
  },
  "figType": "Table",
  "imageText": ["Average", "0.732", "0.698", "0.712", "Dataset-Issue", "0.659", "0.625", "0.640", "Dataset-PR", "0.620", "0.636", "0.625", "Dataset-Commit", "0.787", "0.675", "0.724", "Dataset-Comments", "0.862", "0.855", "0.859"],
  "name": "V",
  "page": 7,
  "regionBoundary": {
    "x1": 328.8,
    "x2": 536.16,
    "y1": 422.88,
    "y2": 476.15999999999997
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/wcre-saner2024/figures/10_1109-SANER60148_2024_00087-TableV-1.png"
}, {
  "caption": "Fig. 3. MT-BERT-SATD Model Architecture: The model comprises of the Embedding, Encoder, Pooler, and four final classifier layers. Four artifacts of data serve as inputs, which are first encoded through the Embedding layer. The Encoder layer, with shared parameters, adjusts the model parameters. The output of the Encoder layer is then fed into the Pooler layer to obtain the final layer representation of the model output. Finally, the data after Pooler is input into the four sub-classifiers to perform the specific SATD classification task.",
  "captionBoundary": {
    "x1": 67.38699340820312,
    "x2": 550.6146240234375,
    "y1": 248.59759521484375,
    "y2": 277.4114990234375
  },
  "figType": "Figure",
  "imageText": ["Online", "Prediction", "BERT", "Training", "Classifier", "Offline", "Linear", "Classifier", "Linear", "Classifier", "Linear", "Classifier", "Linear", "T1", "T2", "T3", "............", "Tn-2", "Tn-1", "Tn", "Embedding", "Pooler", "shared", "layers", "Encoder", "............", ".....", ".....", ".......................", "......", "......", "Layer:", "Multiheaded", "Self-Attention", "+", "MLP", "Layer:", "Multiheaded", "Self-Attention", "+", "MLP", "Layer:", "Multiheaded", "Self-Attention", "+", "MLP", "E1", "E2", "E3", "En-2", "En-1", "En", "Comments", "Feature", "Issue", "Feature", "PR", "Feature", "Commit", "Feature", "Code", "Comments", "Issue", "PR", "Commit", "Code", "SATD", "Trained", "Model", "Comments", "Issue", "PR", "Commit", "Code", "GitHub", "Tracker", "Issue", "Repository", "GitHub"],
  "name": "3",
  "page": 7,
  "regionBoundary": {
    "x1": 135.84,
    "x2": 482.4,
    "y1": 72.96,
    "y2": 236.16
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/wcre-saner2024/figures/10_1109-SANER60148_2024_00087-Figure3-1.png"
}, {
  "caption": "Table II Comprehensive dataset containing four different programming languages and four different artifacts",
  "captionBoundary": {
    "x1": 154.3256378173828,
    "x2": 461.5085144042969,
    "y1": 74.58831787109375,
    "y2": 86.54541015625
  },
  "figType": "Table",
  "imageText": ["Dataset", "Sample", "Source", "Description", "Published", "Year", "Article", "Source", "#Samples", "#SATD", "Reference", "Dataset-06-Comments-Java", "Code", "Comments/java", "Code", "comments", "in", "10", "different", "types", "of", "Java", "projects.", "2017", "TSE", "62275", "4497", "[9]", "Dataset-03-Comments-XML", "Code", "Comments/XML", "Code", "comments", "in", "maven", "build", "systems.", "2021", "TSE", "884", "513", "[16]", "Dataset-05-Comments-Java", "Code", "Comments/java", "Code", "comments", "in", "10", "different", "types", "of", "Java", "projects.", "2021", "TOSEM", "81260", "2995", "[11]", "Dataset-01-Comments-Dockerﬁle", "Code", "Comments/dockerﬁle", "Code", "comments", "from", "ﬁles", "in", "Docker.", "2022", "EMSE", "382", "50", "[14]", "Dataset-02-Comments-Python", "Code", "Comments/python", "Code", "comments", "in", "machine", "learning", "projects.", "2022", "FSE", "856", "789", "[15]", "Dataset-04-Comments-Java", "Code", "Comments/java", "Code", "comments", "in", "SQL", "and", "NO-SQL", "java", "systems.", "2022", "EMSE", "361", "256", "[21]", "Dataset-07-Issue", "Issue", "Trackers", "Issues", "in", "Jira", "and", "Google", "issue", "trackers.", "2022", "EMSE", "23180", "3277", "[17]", "Dataset-08-Issue", "Issue", "Trackers", "R", "package", "issues", "from", "rOpenSci", "and", "Bioconductor.", "2022", "SANER", "1205", "805", "[20]", "Dataset-10-PR", "Pull", "Requests", "Pull", "Requests", "from", "Spark,", "Kafka,", "and", "React.", "2022", "ESEM", "2122", "811", "[19]", "Dataset-09-PR", "Pull", "Requests", "Pull", "Requests", "from", "Apache", "echo-system.", "2023", "EMSE", "5000", "718", "[18]", "Dataset-11-Commits", "Commit", "Messages", "Commit", "Messages", "from", "Apache", "echo-system.", "2023", "EMSE", "5000", "747", "[18]", "Total", "-", "-", "-", "-", "182525", "15458", "-"],
  "name": "II",
  "page": 3,
  "regionBoundary": {
    "x1": 67.67999999999999,
    "x2": 546.24,
    "y1": 89.75999999999999,
    "y2": 186.23999999999998
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/wcre-saner2024/figures/10_1109-SANER60148_2024_00087-TableII-1.png"
}, {
  "caption": "Table VII Cross-artifact prediction performance of our approach.",
  "captionBoundary": {
    "x1": 348.2266845703125,
    "x2": 515.8355102539062,
    "y1": 74.60760498046875,
    "y2": 86.564697265625
  },
  "figType": "Table",
  "imageText": ["Dataset", "New", "Metrics", "Origin", "Drop", "Precision", "Recall", "F1-score", "Dataset-Issue", "0.481", "0.446", "0.463", "0.640", "-27.7%", "Dataset-PR", "0.588", "0.571", "0.579", "0.625", "-7.36%", "Dataset-Commit", "0.670", "0.566", "0.614", "0.724", "-15.2%", "Dataset-Comments", "0.553", "0.739", "0.633", "0.859", "-26.3%", "Average", "0.573", "0.581", "0.572", "0.712", "-19.7%"],
  "name": "VII",
  "page": 8,
  "regionBoundary": {
    "x1": 325.92,
    "x2": 535.1999999999999,
    "y1": 92.64,
    "y2": 161.28
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/wcre-saner2024/figures/10_1109-SANER60148_2024_00087-TableVII-1.png"
}, {
  "caption": "Table VI Comparison of F1-score to other existing methods for recognizing SATDs.",
  "captionBoundary": {
    "x1": 62.722328186035156,
    "x2": 293.25555419921875,
    "y1": 225.67999267578125,
    "y2": 237.6370849609375
  },
  "figType": "Table",
  "imageText": ["Average", "0.546", "0.552", "0.681", "0.712", "Dataset-Issue", "0.488", "0.478", "0.628", "0.640", "Dataset-PR", "0.492", "0.536", "0.617", "0.625", "Dataset-Commits", "0.466", "0.597", "0.652", "0.724", "Dataset-Comments", "0.737", "0.597", "0.827", "0.859", "NLP", "TM", "BERT", "MT-BERT-SATD", "Dataset", "Approach"],
  "name": "VI",
  "page": 8,
  "regionBoundary": {
    "x1": 72.0,
    "x2": 281.28,
    "y1": 243.84,
    "y2": 319.2
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/wcre-saner2024/figures/10_1109-SANER60148_2024_00087-TableVI-1.png"
}, {
  "caption": "Fig. 2. OTM and MTM scenarios.",
  "captionBoundary": {
    "x1": 123.95890045166016,
    "x2": 231.99205017089844,
    "y1": 328.2223205566406,
    "y2": 331.7510070800781
  },
  "figType": "Figure",
  "imageText": ["test", "RQ3", "0.1", "ratio", "test", "sets", "Comments", "Dataset-", "Dataset-", "Commits", "PR", "Dataset-", "Issue", "Dataset-", "train", "BERT", "TM", "NLP", "MT-BERT", "0.9", "ratio", "train", "set", "Comments", "Dataset-", "Dataset-", "Commits", "PR", "Dataset-", "Issue", "Dataset-", "MTM", "RQ2", "RQ1", "test", "Dataset-", "Commits", "PR", "Dataset-", "Issue", "Dataset-", "XML", "Dataset-", "Dataset-", "Python", "Dcokerfile", "Dataset-", "BERT", "TM", "NLP", "MAT", "Pattern", "Dataset-M", "train", "OTM"],
  "name": "2",
  "page": 4,
  "regionBoundary": {
    "x1": 69.6,
    "x2": 286.08,
    "y1": 72.48,
    "y2": 322.08
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/wcre-saner2024/figures/10_1109-SANER60148_2024_00087-Figure2-1.png"
}]