[{
  "caption": "TABLE III TESTING THREE CANDIDATE PROMPTS ON T2C AND C2C GENERATION TASKS.",
  "captionBoundary": {
    "x1": 68.51165771484375,
    "x2": 289.797607421875,
    "y1": 275.98834228515625,
    "y2": 295.97283935546875
  },
  "figType": "Table",
  "imageText": ["C2C", "ChatGPT-task", "10.61", "46.12", "ChatGPT-detail", "15.79", "(+48.82%)", "47.71", "(+03.45%)", "ChatGPT-behaviour", "09.47", "(-10.74%)", "47.38", "(+02.32%)", "T2C", "ChatGPT-task", "05.63", "28.05", "ChatGPT-detail", "14.09", "(+140.27%)", "39.90", "(+42.25%)", "ChatGPT-behaviour", "21.59", "(+283.48%)", "48.69", "(+73.58%)", "Task", "Model", "BLEU", "CodeBLEU"],
  "name": "III",
  "page": 5,
  "regionBoundary": {
    "x1": 65.75999999999999,
    "x2": 290.4,
    "y1": 305.28,
    "y2": 381.12
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/wcre-saner2024/figures/10_1109-SANER60148_2024_00018-TableIII-1.png"
}, {
  "caption": "TABLE IV TESTING THE BEST BASELINES IN RQ1 WITH (OR WITHOUT) THE CONCISENESS REQUEST (C) ON T2C AND C2C GENERATION TASKS.",
  "captionBoundary": {
    "x1": 325.6900329589844,
    "x2": 537.9642333984375,
    "y1": 390.902099609375,
    "y2": 410.8865661621094
  },
  "figType": "Table",
  "imageText": ["C2C", "ChatGPT-detail", "15.79", "47.71", "ChatGPT-detail-C", "16.75", "(+06.08%)", "46.62", "(-02.28%)", "T2C", "ChatGPT-behaviour", "21.59", "48.69", "ChatGPT-behaviour-C", "26.86", "(+24.41%)", "50.18", "(+03.06%)", "Task", "Model", "BLEU", "CodeBLEU"],
  "name": "IV",
  "page": 5,
  "regionBoundary": {
    "x1": 315.84,
    "x2": 546.24,
    "y1": 421.44,
    "y2": 481.44
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/wcre-saner2024/figures/10_1109-SANER60148_2024_00018-TableIV-1.png"
}, {
  "caption": "TABLE VI TESTING THE BEST BASELINES IN RQ3 ON T2C AND C2C GENERATION TASKS IN FIVE ROUNDS (RQ1-R5), WHERE “MIN”, “MAX”, “AVG”, “STD” STAND FOR THE MINIMUM, MAXIMUM, AVERAGE AND STANDARD DEVIATION OF THE GENERATION ACCURACY.",
  "captionBoundary": {
    "x1": 315.6829528808594,
    "x2": 543.5386352539062,
    "y1": 74.85100555419922,
    "y2": 111.36065673828125
  },
  "figType": "Table",
  "imageText": ["MIN", "16.82", "48.80", "MAX", "17.34", "49.17", "AVG", "17.18", "48.86", "STD", "00.21", "00.33", "R1", "16.82", "48.80", "R2", "17.34", "49.17", "R3", "17.23", "48.38", "R4", "17.32", "49.15", "R5", "17.21", "48.80", "C2C", "MIN", "26.86", "50.07", "MAX", "27.02", "50.20", "AVG", "26.93", "50.16", "STD", "00.08", "00.05", "R1", "26.86", "50.18", "R2", "26.85", "50.07", "R3", "27.02", "50.18", "R4", "26.92", "50.20", "R5", "27.00", "50.17", "T2C", "Task", "Model", "BLEU", "CodeBLEU"],
  "name": "VI",
  "page": 6,
  "regionBoundary": {
    "x1": 316.8,
    "x2": 541.4399999999999,
    "y1": 120.96,
    "y2": 305.28
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/wcre-saner2024/figures/10_1109-SANER60148_2024_00018-TableVI-1.png"
}, {
  "caption": "TABLE V TESTING THE BEST BASELINE IN RQ2 WITH (OR WITHOUT) THE SESSION SETTING (S) ON T2C AND C2C GENERATION TASKS.",
  "captionBoundary": {
    "x1": 65.51184844970703,
    "x2": 292.8701477050781,
    "y1": 299.378662109375,
    "y2": 319.3622741699219
  },
  "figType": "Table",
  "imageText": ["C2C", "ChatGPT-detail", "15.79", "47.71", "ChatGPT-detail-S", "16.82", "(+06.52%)", "48.80", "(+02.28%)", "T2C", "ChatGPT-behaviour-C", "26.86", "50.18", "ChatGPT-behaviour-CS", "29.29", "(+09.05%)", "49.74", "(-00.88%)", "Task", "Model", "BLEU", "CodeBLEU"],
  "name": "V",
  "page": 6,
  "regionBoundary": {
    "x1": 63.839999999999996,
    "x2": 292.32,
    "y1": 329.76,
    "y2": 389.28
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/wcre-saner2024/figures/10_1109-SANER60148_2024_00018-TableV-1.png"
}, {
  "caption": "TABLE VIII QUALITY ANALYSIS OF THE CODE GENERATED BY CHATGPT-BEST AND THE CORRESPONDING GROUND-TRUTH ON T2C AND C2C GENERATION TASKS.",
  "captionBoundary": {
    "x1": 73.50454711914062,
    "x2": 546.5614013671875,
    "y1": 74.69084930419922,
    "y2": 86.413330078125
  },
  "figType": "Table",
  "imageText": ["C2C", "Generated", "Code", "0", "0", "0", "0", "56", "6", "62", "Ground-Truth", "0", "0", "0", "0", "10", "7", "17", "T2C", "Generated", "Code", "0", "1", "0", "0", "0", "29", "30", "Ground-Truth", "0", "0", "0", "0", "1", "34", "35", "Task", "Data", "#Bug", "#Vulnerability", "#Code", "Smell", "Total", "Blocker", "Critical", "Blocker", "Critical", "Blocker", "Critical"],
  "name": "VIII",
  "page": 9,
  "regionBoundary": {
    "x1": 72.96,
    "x2": 543.36,
    "y1": 96.96,
    "y2": 167.04
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/wcre-saner2024/figures/10_1109-SANER60148_2024_00018-TableVIII-1.png"
}, {
  "caption": "TABLE I ON 100 SAMPLES RANDOMLY SELECTED FROM TRAINING DATA OF EACH GENERATION TASK. NOTE THAT P5(API) INDICATES THAT WE ONLY USED THE API PART OF THE PROMPT P5.",
  "captionBoundary": {
    "x1": 63.773414611816406,
    "x2": 295.2563781738281,
    "y1": 378.0848083496094,
    "y2": 398.06842041015625
  },
  "figType": "Table",
  "imageText": ["C2C", "P1", "09.76", "39.37", "P1+P3", "08.55", "(-12.40%)", "45.28", "(+15.01%)", "P4+P3", "15.44", "(+58.20%)", "45.00", "(+14.30%)", "P5(API)+P3", "13.37", "(+36.99%)", "46.17", "(+17.27%)", "P5+P3", "08.90", "(-08.81%)", "46.88", "(+19.08%)", "T2C", "P1", "05.29", "22.76", "P2+P1", "10.42", "(+96.98%)", "25.05", "(+10.06%)", "P2+P1+P3", "13.11", "(+147.83%)", "36.00", "(+58.17%)", "P2+P5(API)+P3", "22.14", "(+318.53%)", "44.18", "(+94.11%)", "P2+P5+P3", "27.48", "(+419.47%)", "46.78", "(+105.54%)", "Task", "Model", "BLEU", "CodeBLEU"],
  "name": "I",
  "page": 3,
  "regionBoundary": {
    "x1": 63.839999999999996,
    "x2": 295.2,
    "y1": 407.52,
    "y2": 517.4399999999999
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/wcre-saner2024/figures/10_1109-SANER60148_2024_00018-TableI-1.png"
}, {
  "caption": "TABLE VII COMPARISONS BETWEEN THE BEST PROMPTS (CHATGPT-BEST) AND THE STATE-OF-THE-ART FINE-TUNED LLMS REPORTED IN [5] AND [32] ON T2C AND C2C GENERATION TASKS.",
  "captionBoundary": {
    "x1": 71.7933349609375,
    "x2": 545.1530151367188,
    "y1": 74.58696746826172,
    "y2": 94.571533203125
  },
  "figType": "Table",
  "imageText": ["65.00", "85.27", "PLBART", "A", "sequence-to-sequence", "model", "capable", "of", "performing", "a", "broad", "spectrum", "of", "program", "and", "language", "understanding", "and", "generation", "tasks", "[33].", "71.99", "80.18", "RoBERTa", "It", "is", "based", "on", "the", "architecture", "of", "the", "BERT", "model", "and", "is", "pre-trained", "on", "a", "large", "corpus", "of", "text", "using", "a", "masked", "language", "modeling", "objective", "[57].", "72.14", "79.41", "CodeBERT", "A", "bidirectional", "encoder", "representations", "from", "transformers", "(BERT)", "model", "with", "pre-trained", "with", "six", "programming", "languages", "[11].", "50.47", "61.59", "Transformer", "A", "sequence-to-sequence", "encoder-decoder", "model", "with", "self-attention", "mechanism", "[26].", "16.82", "48.80", "ChatGPT-best", "ChatGPT-detail-S,", "the", "ChatGPT", "works", "with", "an", "updated", "task", "prompt,", "processing", "prompt,", "and", "continuous", "session.", "40.06", "43.48", "PBSMT", "A", "traditional", "phase-based", "machine", "translation", "method", "that", "uses", "statistical", "models", "to", "translate", "text", "from", "one", "language", "to", "another.", "[58]", "C2C", "26.86", "50.18", "ChatGPT-best", "ChatGPT-behaviour-C,", "the", "ChatGPT", "works", "with", "context", "prompt,", "behaviour", "prompt,", "processing", "prompt,", "and", "conciseness", "request.", "CodeT5", "A", "uniﬁed", "pre-trained", "encoder-decoder", "Transformer", "model", "that", "better", "leverages", "the", "code", "semantics", "conveyed", "from", "the", "developer-assigned", "identiﬁers", "[32].", "41.48", "44.10", "36.69", "38.52", "PLBART", "A", "sequence-to-sequence", "model", "capable", "of", "performing", "a", "broad", "spectrum", "of", "program", "and", "language", "understanding", "and", "generation", "tasks", "[33].", "CodeGPT-adapted", "CodeGPT", "is", "continually", "trained", "on", "the", "code", "corpus", "[5].", "32.79", "35.98", "28.69", "32.71", "CodeGPT", "A", "Transformer-based", "language", "model", "that", "has", "the", "same", "model", "architecture", "and", "training", "objective", "of", "GPT-2", "and", "pre-trained", "on", "the", "programming", "language", "(PL)", "[5].", "24.40", "29.46", "Seq2Action+MAML", "A", "context-aware", "encoder-decoder", "mode", "that", "leverages", "model-agnostic", "meta-learning", "(MAML)", "[57].", "Seq2Seq", "An", "RNN-based", "sequence", "to", "sequence", "model", "[56].", "21.31", "26.39", "T2C", "Task", "Model", "Description", "BLEU", "CodeBLEU"],
  "name": "VII",
  "page": 8,
  "regionBoundary": {
    "x1": 77.75999999999999,
    "x2": 548.16,
    "y1": 103.67999999999999,
    "y2": 387.84
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/wcre-saner2024/figures/10_1109-SANER60148_2024_00018-TableVII-1.png"
}]