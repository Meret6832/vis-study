[{
  "caption": "Table 1: Descriptive Statistics for inference JIRA Dataset",
  "captionBoundary": {
    "x1": 192.05999755859375,
    "x2": 419.635009765625,
    "y1": 85.72634887695312,
    "y2": 91.35699462890625
  },
  "figType": "Table",
  "imageText": ["Mule", "Studio", "732", "1", "34", "6.40", "5", "5", "5.38", "Spring", "Spring", "XD", "3056", "1", "40", "3.66", "3", "3", "2.87", "Talendforge", "Talend", "Data", "Quality", "1136", "1", "40", "6.25", "5", "8", "5.29", "Talend", "ESB", "775", "1", "13", "2.17", "2", "1", "1.50", "Moodle", "Moodle", "1166", "1", "100", "15.54", "8", "8", "21.65", "Lsstcorp", "Data", "Management", "4030", "1", "100", "9.40", "4", "1", "16.37", "Mulesoft", "Mule", "889", "1", "21", "5.08", "5", "5", "3.50", "Clover", "361", "1", "40", "4.57", "2", "1", "6.46", "JIRA", "Software", "286", "1", "20", "4.59", "3", "5", "3.59", "Titanium", "2122", "1", "34", "6.17", "5", "5", "4.99", "DuraSpace", "DuraCloud", "613", "1", "16", "2.10", "1", "1", "1.95", "Atlassian", "Bamboo", "374", "1", "20", "2.30", "2", "1", "1.92", "Apache", "Mesos", "1562", "1", "40", "3.04", "3", "3", "2.38", "Usergrid", "333", "1", "8", "3.06", "3", "3", "1.44", "Appcelerator", "Appcelerator", "Studio", "2876", "1", "40", "5.63", "5", "5", "3.31", "Aptana", "Studio", "771", "1", "40", "8.26", "8", "8", "5.95", "repository", "Project", "issue", "min", "SP", "max", "SP", "mean", "SP", "median", "SP", "mode", "SP", "std", "SP"],
  "name": "1",
  "page": 5,
  "regionBoundary": {
    "x1": 128.64,
    "x2": 483.35999999999996,
    "y1": 105.6,
    "y2": 252.0
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/iwpc-icpc2024/figures/10_1145-3643916_3644417-Table1-1.png"
}, {
  "caption": "Figure 1: Comparison of cooperative reasoning with traditional estimation methods.",
  "captionBoundary": {
    "x1": 53.79800033569336,
    "x2": 295.6368408203125,
    "y1": 357.7083435058594,
    "y2": 374.2980041503906
  },
  "figType": "Figure",
  "imageText": ["Given", "task", "description", "cooperative", "reasoning", "That's", "great!", "That", "will", "be", "our", "final", "answer.", "I", "give", "this", "answer", "full", "marks", "This", "task", "can", "be", "summarized", "as", "improving", "home", "wiki", "page.", "The", "story", "point", "of", "this", "task", "is", "[ANS]", "2.", "solver", "verifiers", "generator", "Add", "more", "structure,", "more", "easily", "find", "the", "reference", "guide.", "The", "style", "in", "the", "https://xxx.com/wiki", "is", "nice.", "2.0", "Given", "task", "title", "Home", "wiki", "page", "improvements.", "traditional", "methods"],
  "name": "1",
  "page": 1,
  "regionBoundary": {
    "x1": 53.76,
    "x2": 294.24,
    "y1": 130.56,
    "y2": 344.15999999999997
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/iwpc-icpc2024/figures/10_1145-3643916_3644417-Figure1-1.png"
}, {
  "caption": "Table 2: The Mean Absolute Error of our CRSP compared to other baselines.",
  "captionBoundary": {
    "x1": 152.31700134277344,
    "x2": 459.37554931640625,
    "y1": 85.72634887695312,
    "y2": 91.35699462890625
  },
  "figType": "Table",
  "imageText": ["Talendforge", "Talend", "Data", "Quality", "1.87", "3.89", "4.86", "4.86", "5.28", "5.36", "Talend", "ESB", "0.88", "0.94", "0.99", "0.99", "1.10", "1.15", "Spring", "Spring", "XD", "1.92", "1.97", "2.01", "2.01", "3.79", "3.15", "Mulesoft", "Mule", "2.37", "2.53", "2.57", "2.57", "3.61", "3.88", "Mule", "Studio", "2.93", "3.68", "3.67", "3.49", "5.92", "5.77", "Lsstcorp", "Data", "Management", "5.53", "5.57", "8.09", "7.49", "10.96", "7.94", "Moodle", "Moodle", "5.17", "10.10", "12.26", "11.42", "13.11", "12.18", "JIRA", "Software", "1.72", "1.87", "2.56", "2.21", "2.78", "2.84", "Atlassian", "Bamboo", "0.68", "0.76", "1.01", "1.01", "0.87", "1.14", "Clover", "3.35", "3.95", "4.64", "4.00", "3.88", "3.64", "DuraSpace", "DuraCloud", "0.85", "0.88", "0.99", "0.99", "1.25", "1.37", "Titanium", "2.06", "2.12", "2.91", "2.87", "4.26", "3.77", "Appcelerator", "Appcelerator", "Studio", "1.36", "1.38", "1.89", "1.90", "4.05", "1.8", "Aptana", "Studio", "3.54", "3.55", "3.78", "3.80", "6.21", "3.65", "Apache", "Mesos", "1.09", "1.21", "1.34", "1.32", "1.68", "1.24", "Usergrid", "0.86", "1.09", "1.07", "1.02", "2.31", "2.19", "repository", "project", "CRSP", "GPT2SP", "BERT", "BERT-cot", "mode", "median"],
  "name": "2",
  "page": 6,
  "regionBoundary": {
    "x1": 151.68,
    "x2": 460.32,
    "y1": 105.6,
    "y2": 288.0
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/iwpc-icpc2024/figures/10_1145-3643916_3644417-Table2-1.png"
}, {
  "caption": "Figure 6: An example of CRSP output.",
  "captionBoundary": {
    "x1": 229.1580047607422,
    "x2": 382.8351745605469,
    "y1": 237.74734497070312,
    "y2": 243.37799072265625
  },
  "figType": "Figure",
  "imageText": ["Answer", "1", "Generated", "reasoning", "path", "[THOUGHT]This", "task", "can", "be", "summerized", "as", "<<Fix", "data", "migration", "format", "lifecycle", "on", "initial", "setup>>.", "The", "story", "point", "of", "this", "task", "is", "[ANS]", "1", "<|endofsentence|>.", "Question", "[QUES]", "Admins", "then", "have", "to", "run", "the", "migration", "via", "PUT", "/system/migrate/run", "This", "causes", "an", "unnecessary", "migration", "from", "V0", "to", "current.", "Instead,", "on", "our", "initial", "setup", "in", "CPSetup.java,", "we", "should", "perform", "the", "following.", "#", "Create", "keyspaces", "and", "column", "families", "#", "Perform", "the", "data", "migration,", "which", "will", "simply", "set", "the", "current", "max", "version", "BEFORE", "data", "is", "written", "#", "Write", "the", "initial", "root", "application", "state"],
  "name": "6",
  "page": 9,
  "regionBoundary": {
    "x1": 52.8,
    "x2": 559.1999999999999,
    "y1": 82.56,
    "y2": 224.16
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/iwpc-icpc2024/figures/10_1145-3643916_3644417-Figure6-1.png"
}, {
  "caption": "Figure 7: Comparison of different maximally inference iterations.",
  "captionBoundary": {
    "x1": 53.79800033569336,
    "x2": 295.642578125,
    "y1": 687.4703369140625,
    "y2": 704.0599975585938
  },
  "figType": "Figure",
  "imageText": [],
  "name": "7",
  "page": 9,
  "regionBoundary": {
    "x1": 52.8,
    "x2": 295.2,
    "y1": 480.96,
    "y2": 674.4
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/iwpc-icpc2024/figures/10_1145-3643916_3644417-Figure7-1.png"
}, {
  "caption": "Figure 2: Example of a story point estimation process for a restaurant’s menu management scenario.",
  "captionBoundary": {
    "x1": 53.79800033569336,
    "x2": 294.0323486328125,
    "y1": 208.46633911132812,
    "y2": 225.0560302734375
  },
  "figType": "Figure",
  "imageText": ["DONE", "Fix", "Version/s:", "1.3.2", "Resolution:", "Done", "Status:", "prices.", "For", "different", "types", "of", "dishes,", "classify", "them", "into", "different", "categories.", "Design", "an", "easy-to-use", "management", "interface", "that", "displays", "restaurant", "dishes", "and", "their", "Description:", "Story", "Points:", "5", "Affects", "Version/s:", "1.1.2", "Priority:", "major", "Type:", "Story", "Design", "menu", "page", "RESTAURANT", "/", "US-1"],
  "name": "2",
  "page": 2,
  "regionBoundary": {
    "x1": 57.12,
    "x2": 292.32,
    "y1": 86.88,
    "y2": 189.6
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/iwpc-icpc2024/figures/10_1145-3643916_3644417-Figure2-1.png"
}, {
  "caption": "Table 4: MAE comparison of cross-project generator and within-project generator.",
  "captionBoundary": {
    "x1": 317.6050109863281,
    "x2": 558.18994140625,
    "y1": 430.99334716796875,
    "y2": 447.5830078125
  },
  "figType": "Table",
  "imageText": ["Talendforge", "Talend", "Data", "Quality", "1.87", "2.27", "17.62", "Talend", "ESB", "0.88", "0.63", "-28.41", "Mulesoft", "Mule", "2.37", "1.92", "-18.99", "Mule", "Studio", "2.93", "3.57", "17.93", "JIRA", "Software", "1.72", "1.62", "-5.81", "Atlassian", "Bamboo", "0.68", "0.84", "19.05", "Clover", "3.35", "2.98", "-11.04", "Titanium", "2.06", "2.2", "6.36", "Appcelerator", "Appcelerator", "Studio", "1.36", "1.85", "26.49", "Aptana", "Studio", "3.54", "2.73", "-22.88", "Apache", "Mesos", "1.09", "1.17", "6.84", "Usergrid", "0.86", "1.07", "19.63", "repository", "project", "cross", "within", "improvement(%)"],
  "name": "4",
  "page": 7,
  "regionBoundary": {
    "x1": 320.64,
    "x2": 555.36,
    "y1": 462.24,
    "y2": 595.1999999999999
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/iwpc-icpc2024/figures/10_1145-3643916_3644417-Table4-1.png"
}, {
  "caption": "Table 3: Examples of reasoning paths generated by generator with different parameters.",
  "captionBoundary": {
    "x1": 128.10699462890625,
    "x2": 483.58184814453125,
    "y1": 85.72634887695312,
    "y2": 91.35699462890625
  },
  "figType": "Table",
  "imageText": ["GPT-J", "6B", "6.05B", "This", "task", "can", "be", "summerized", "as", "<<Context", "info", "popup", "blocks", "code", "when", "using", "mutli-line", "function", "invocations>>.", "The", "story", "point", "of", "this", "task", "is", "[ANS]1.", "GPT-Neo-1.3B", "1.37B", "This", "task", "can", "be", "summerized", "as", "<<Context", "information", "popup", "when", "using", "function", "invocations>>.", "The", "story", "point", "of", "this", "task", "is", "[ANS]1.", "GPT-Neo-2.7B", "2.72B", "This", "task", "can", "be", "summerized", "as", "<<Context", "information", "popup", "blocks", "when", "using", "function", "invocations>>.", "The", "story", "point", "of", "this", "task", "is", "[ANS]1.", "BERT", "110M", "This", "task", "can", "be", "summerized", "as", "as", "as", "as", "<<code", "text", "task>>.", "The", "story", "is", "is", "is", "is", "two.", "GPT2-large", "812M", "This", "task", "can", "be", "summerized", "as", "<<multi-blocks", "pop>>.", "The", "story", "point", "of", "this", "task", "is", "[ans]4.", "model", "parameters", "generated", "example"],
  "name": "3",
  "page": 7,
  "regionBoundary": {
    "x1": 81.6,
    "x2": 530.4,
    "y1": 105.6,
    "y2": 189.12
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/iwpc-icpc2024/figures/10_1145-3643916_3644417-Table3-1.png"
}, {
  "caption": "Figure 3: Framework of our proposed CRSP.",
  "captionBoundary": {
    "x1": 217.02699279785156,
    "x2": 394.9661560058594,
    "y1": 381.4083557128906,
    "y2": 387.03900146484375
  },
  "figType": "Figure",
  "imageText": ["Linear", "solver", "final", "answer", "2", "Decsion", "Making", "candidate", "solutions", "story", "point", "1", "2", "3", "5", "8", "Filtering", "Random", "Forest", "low", "perplexity", "negative", "scores", "Solutions", "Dataset", "D*", "question：We've", "observed", "issues", "where", "the", "masters", "are", "slow", "to", "respond.", "generated", "reasoning", "path：This", "task", "can", "be", "summarized", "as", "deal", "memory", "issue.", "The", "story", "point", "of", "this", "task", "is", "2.", "answer：2", "collaborate", "[EOS]", "or", "Max", "Length", "Monte", "Carlo", "Tree", "Search", "Selection", "SimulationExpansion", "Backpropagation", "×", "N", "×", "N", "×", "N", "generator(GPT-Neo)", "verifier(DeBERTa)", "Enhanced", "Mask", "Decoder", "Absolute", "Position", "Embedding", "Relative", "Position", "Embedding", "Transformer", "layers", "Embedding", "Step", "verifer：Sentence", "1", "not", "good.", "Sentence", "2", "good.", "Path", "verifer：Result", "not", "good.", "verifier", "Fine-tuning", "verifier", "generated", "reasoning", "path：This", "task", "can", "be", "summarized", "as", "system", "response", "slow.", "The", "story", "point", "of", "this", "task", "is", "3.", "answer：3", "Generate", "data", "Generator", "can", "generate", "generated", "reasoning", "path,", "and", "answer", "now.", "generator", "question：We've", "observed", "issues", "where", "the", "masters", "are", "slow", "to", "respond.", "reasoning", "path：This", "task", "can", "be", "summarized", "as", "Deal", "the", "memory", "issue.", "The", "story", "point", "of", "this", "task", "is", "2.", "ground", "truth：2", "Story", "Point", "Estimation", "Dataset", "D", "Fine-tuning", "generator", "Layer", "Norm", "Feed", "Forward", "Layer", "Norm", "Masked", "Multi-Head", "attention", "Embedding", "Model", "Construction", "Phase", "Monte", "Carlo", "Tree", "Search", "Phase", "Model", "Inference", "Phase"],
  "name": "3",
  "page": 3,
  "regionBoundary": {
    "x1": 65.75999999999999,
    "x2": 555.36,
    "y1": 96.0,
    "y2": 359.03999999999996
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/iwpc-icpc2024/figures/10_1145-3643916_3644417-Figure3-1.png"
}, {
  "caption": "Figure 5: Comparison of different solver strategies on 16 open source software projects.",
  "captionBoundary": {
    "x1": 129.447998046875,
    "x2": 482.5379943847656,
    "y1": 414.32135009765625,
    "y2": 419.9519958496094
  },
  "figType": "Figure",
  "imageText": [],
  "name": "5",
  "page": 8,
  "regionBoundary": {
    "x1": 52.8,
    "x2": 559.1999999999999,
    "y1": 82.56,
    "y2": 401.28
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/iwpc-icpc2024/figures/10_1145-3643916_3644417-Figure5-1.png"
}, {
  "caption": "Figure 4: Example of one MCTS iteration. a) Initialization: initialize the root node of the Monte Carlo tree. b) Selection: selects the node with the largest PUCT value. c) Expansion: use generator to generate new tokens. d) Simulation: generate a complete answer. e) Backpropagation: back propagate the datas and update.",
  "captionBoundary": {
    "x1": 53.79800033569336,
    "x2": 558.177978515625,
    "y1": 246.67733764648438,
    "y2": 274.2249755859375
  },
  "figType": "Figure",
  "imageText": ["R(n2)=0", "N(s,n2)=0", "R(n1)=0.65", "N(s,n1)=1", "R(n2)=0", "N(s,n2)=0", "R(n1)=0", "N(s,n1)=0", "R(nα)=0.99", "N(s,nα)=1", "is", "reducing", "α", "The", "story", "point", "of", "this", "task", "is", "[ANS]", "2.", "R(n4)=0.63", "N(s,n4)=1", "R(n3)=0.35", "N(s,n3)=0", "3", "4", "can", "be", "summerized", "R(n0)=0", "N(s,n0)=0", "1", "2the", "task", "the", "story", "point", "0", "R(nα)=0.99", "N(s,nα)=0", "e)", "backpropagation", "is", "reducing", "α", "The", "story", "point", "of", "this", "task", "is", "[ANS]", "2.", "R(n4)=0.54", "N(s,n4)=0", "R(n3)=0", "N(s,n3)=0", "3", "4", "can", "be", "summerized", "R(n0)=0", "N(s,n0)=0", "1", "2the", "task", "the", "story", "point", "0", "d)", "simulation", "R(n4)=0.54", "N(s,n4)=0", "can", "be", "summerizedR(n3)=0", "N(s,n3)=0", "is", "reducing", "3", "4", "R(n2)=0", "N(s,n2)=0", "R(n1)=0", "N(s,n1)=0", "R(n0)=0", "N(s,n0)=0", "1", "2the", "task", "the", "story", "point", "0", "c)", "expansion", "R(n2)=0", "N(s,n2)=0", "R(n1)=0", "N(s,n1)=0", "b)", "selection", "R(n0)=0", "N(s,n0)=0", "R(n0)=0", "N(s,n0)=0", "0", "a)", "initialization", "1", "2the", "task", "the", "story", "point", "0"],
  "name": "4",
  "page": 4,
  "regionBoundary": {
    "x1": 78.72,
    "x2": 554.88,
    "y1": 89.75999999999999,
    "y2": 228.95999999999998
  },
  "renderDpi": 150,
  "renderURL": "../datacollection/pdf_analysis/iwpc-icpc2024/figures/10_1145-3643916_3644417-Figure4-1.png"
}]